{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "This notebook is part of the `deepcell-tf` documentation: https://deepcell.readthedocs.io/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a segmentation model\n",
    "\n",
    "`deepcell-tf` leverages [Jupyter Notebooks](https://jupyter.org) in order to train models. Example notebooks are available for most model architectures in the [notebooks folder](https://github.com/vanvalenlab/deepcell-tf/tree/master/notebooks). Most notebooks are structured similarly to this example and thus this notebook serves as a core reference for the deepcell approach to model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.feature import peak_local_max\n",
    "import tensorflow as tf\n",
    "\n",
    "from deepcell.applications import NuclearSegmentation\n",
    "from deepcell.image_generators import CroppingDataGenerator\n",
    "from deepcell.losses import weighted_categorical_crossentropy\n",
    "from deepcell.model_zoo.panopticnet import PanopticNet\n",
    "from deepcell.utils.train_utils import count_gpus, rate_scheduler\n",
    "from deepcell_toolbox.deep_watershed import deep_watershed\n",
    "from deepcell_toolbox.metrics import Metrics\n",
    "from deepcell_toolbox.processing import histogram_normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/notebooks/data'\n",
    "model_path = 'NuclearSegmentation'\n",
    "metrics_path = 'metrics.yaml'\n",
    "train_log = 'train_log.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the data\n",
    "\n",
    "The DynamicNuclearNet tracking dataset can be downloaded from https://datasets.deepcell.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(os.path.join(data_dir, 'train.npz')) as data:\n",
    "    X_train = data['X']\n",
    "    y_train = data['y']\n",
    "    \n",
    "with np.load(os.path.join(data_dir, 'val.npz')) as data:\n",
    "    X_val = data['X']\n",
    "    y_val = data['y']\n",
    "    \n",
    "with np.load(os.path.join(data_dir, 'test.npz')) as data:\n",
    "    X_test = data['X']\n",
    "    y_test = data['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of DeepCell models support a variety backbone choices specified in the “backbone” parameter. Backbones are provided through keras_applications and can be instantiated with weights that are pretrained on ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "backbone = \"efficientnetv2bl\"\n",
    "location = True\n",
    "pyramid_levels = [\"P1\",\"P2\",\"P3\",\"P4\",\"P5\",\"P6\",\"P7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Augmentation and transform parameters\n",
    "seed = 0\n",
    "min_objects = 1\n",
    "zoom_min = 0.75\n",
    "crop_size = 256\n",
    "outer_erosion_width = 1\n",
    "inner_distance_alpha = \"auto\"\n",
    "inner_distance_beta = 1\n",
    "inner_erosion_width = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Post processing parameters\n",
    "maxima_threshold = 0.1\n",
    "interior_threshold = 0.01\n",
    "exclude_border = False\n",
    "small_objects_threshold = 0\n",
    "min_distance = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "epochs = 16\n",
    "batch_size = 16\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation parameters\n",
    "zoom_max = 1 / zoom_min\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = histogram_normalization(X_train)\n",
    "X_val = histogram_normalization(X_val)\n",
    "\n",
    "# use augmentation for training but not validation\n",
    "datagen = CroppingDataGenerator(\n",
    "    rotation_range=180,\n",
    "    zoom_range=(zoom_min, zoom_max),\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    crop_size=(crop_size, crop_size),\n",
    ")\n",
    "\n",
    "datagen_val = CroppingDataGenerator(\n",
    "    crop_size=(crop_size, crop_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\"inner-distance\", \"outer-distance\", \"fgbg\"]\n",
    "\n",
    "transforms_kwargs = {\n",
    "    \"outer-distance\": {\"erosion_width\": outer_erosion_width},\n",
    "    \"inner-distance\": {\n",
    "        \"alpha\": inner_distance_alpha,\n",
    "        \"beta\": inner_distance_beta,\n",
    "        \"erosion_width\": inner_erosion_width,\n",
    "    },\n",
    "}\n",
    "\n",
    "train_data = datagen.flow(\n",
    "    {'X': X_train, 'y': y_train},\n",
    "    seed=seed,\n",
    "    min_objects=min_objects,\n",
    "    transforms=transforms,\n",
    "    transforms_kwargs=transforms_kwargs,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "print(\"Created training data generator.\")\n",
    "\n",
    "val_data = datagen_val.flow(\n",
    "    {'X': X_val, 'y': y_val},\n",
    "    seed=seed,\n",
    "    min_objects=min_objects,\n",
    "    transforms=transforms,\n",
    "    transforms_kwargs=transforms_kwargs,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "print(\"Created validation data generator.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the data generator output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = train_data.next()\n",
    "\n",
    "img = inputs[0]\n",
    "inner_distance = outputs[0]\n",
    "outer_distance = outputs[1]\n",
    "fgbg = outputs[2]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 15))\n",
    "\n",
    "axes[0].imshow(img[..., 0])\n",
    "axes[0].set_title('Source Image')\n",
    "\n",
    "axes[1].imshow(inner_distance[0, ..., 0])\n",
    "axes[1].set_title('Inner Distance')\n",
    "\n",
    "axes[2].imshow(outer_distance[0, ..., 0])\n",
    "axes[2].set_title('Outer Distance')\n",
    "\n",
    "axes[3].imshow(fgbg[0, ..., 0])\n",
    "axes[3].set_title('Foreground/Background')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the PanopticNet Model\n",
    "\n",
    "Here we instantiate a `PanopticNet` model from `deepcell.model_zoo` using 3 semantic heads:\n",
    "inner distance (1 class),\n",
    "outer distance (1 class),\n",
    "foreground/background distance (2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (crop_size, crop_size, 1)\n",
    "\n",
    "model = PanopticNet(\n",
    "    backbone=backbone,\n",
    "    input_shape=input_shape,\n",
    "    norm_method=None,\n",
    "    num_semantic_classes=[1, 1, 2],  # inner distance, outer distance, fgbg\n",
    "    location=location, \n",
    "    include_top=True,\n",
    "    backbone_levels=[\"C1\", \"C2\", \"C3\", \"C4\", \"C5\"],\n",
    "    pyramid_levels=pyramid_levels,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loss function for each semantic head\n",
    "\n",
    "Each semantic head is trained with it's own loss function. Mean Square Error is used for regression-based heads, whereas `weighted_categorical_crossentropy` is used for classification heads.\n",
    "\n",
    "The losses are saved as a dictionary and passed to `model.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def semantic_loss(n_classes):\n",
    "    def _semantic_loss(y_pred, y_true):\n",
    "        if n_classes > 1:\n",
    "            return 0.01 * weighted_categorical_crossentropy(\n",
    "                y_pred, y_true, n_classes=n_classes\n",
    "            )\n",
    "        return tf.keras.losses.MSE(y_pred, y_true)\n",
    "\n",
    "    return _semantic_loss\n",
    "\n",
    "loss = {}\n",
    "\n",
    "# Give losses for all of the semantic heads\n",
    "for layer in model.layers:\n",
    "    if layer.name.startswith(\"semantic_\"):\n",
    "        n_classes = layer.output_shape[-1]\n",
    "        loss[layer.name] = semantic_loss(n_classes)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=lr, clipnorm=0.001)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Call `fit` on the compiled model, along with a default set of callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear clutter from previous TensorFlow graphs.\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "monitor = \"val_loss\"\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(train_log)\n",
    "\n",
    "# Create callbacks for early stopping and pruning.\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        model_path,\n",
    "        monitor=monitor,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        save_weights_only=False,\n",
    "    ),\n",
    "    tf.keras.callbacks.LearningRateScheduler(rate_scheduler(lr=lr, decay=0.99)),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=monitor,\n",
    "        factor=0.1,\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        min_delta=0.0001,\n",
    "        cooldown=0,\n",
    "        min_lr=0,\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    csv_logger,\n",
    "]\n",
    "\n",
    "print(f\"Training on {count_gpus()} GPUs.\")\n",
    "\n",
    "# Train model.\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.y.shape[0] // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=val_data.y.shape[0] // batch_size,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "print(\"Final\", monitor, \":\", history.history[monitor][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save prediction model\n",
    "\n",
    "We can now create a new prediction model without the foreground background semantic head. While this head is very useful during training, the output is unused during prediction. By using `model.load_weights(path, by_name=True)`, the semantic head can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    weights_path = os.path.join(str(tmpdirname), \"model_weights.h5\")\n",
    "    model.save_weights(weights_path, save_format=\"h5\")\n",
    "    prediction_model = PanopticNet(\n",
    "        backbone=backbone,\n",
    "        input_shape=input_shape,\n",
    "        norm_method=None,\n",
    "        num_semantic_heads=2,\n",
    "        num_semantic_classes=[1, 1],  # inner distance, outer distance\n",
    "        location=location,  # should always be true\n",
    "        include_top=True,\n",
    "        backbone_levels=[\"C1\", \"C2\", \"C3\", \"C4\", \"C5\"],\n",
    "        pyramid_levels=pyramid_levels,\n",
    "    )\n",
    "    prediction_model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = histograph_normalization(X_test)\n",
    "\n",
    "test_images = prediction_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = np.random.choice(X_test.shape[0])\n",
    "print(index)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 20))\n",
    "\n",
    "masks = deep_watershed(\n",
    "    test_images,\n",
    "    radius=radius,\n",
    "    maxima_threshold=maxima_threshold,\n",
    "    interior_threshold=interior_threshold,\n",
    "    exclude_border=exclude_border,\n",
    "    small_objects_threshold=small_objects_threshold,\n",
    "    min_distance=min_distance\n",
    ")\n",
    "\n",
    "# calculated in the postprocessing above, but useful for visualizing\n",
    "inner_distance = test_images[0]\n",
    "outer_distance = test_images[1]\n",
    "\n",
    "coords = peak_local_max(\n",
    "    inner_distance[index],\n",
    "    min_distance=min_distance\n",
    ")\n",
    "\n",
    "# raw image with centroid\n",
    "axes[0].imshow(X_test[index, ..., 0])\n",
    "axes[0].scatter(coords[..., 1], coords[..., 0],\n",
    "                color='r', marker='.', s=10)\n",
    "\n",
    "axes[1].imshow(inner_distance[index, ..., 0], cmap='jet')\n",
    "axes[2].imshow(outer_distance[index, ..., 0], cmap='jet')\n",
    "axes[3].imshow(masks[index, ...], cmap='jet')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results\n",
    "\n",
    "The `deepcell.metrics` package is used to measure advanced metrics for instance segmentation predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = model.predict(X_test)\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for i in range(outputs[0].shape[0]):\n",
    "\n",
    "    mask = deep_watershed(\n",
    "        [t[[i]] for t in outputs],\n",
    "        radius=radius,\n",
    "        maxima_threshold=maxima_threshold,\n",
    "        interior_threshold=interior_threshold,\n",
    "        exclude_border=exclude_border,\n",
    "        small_objects_threshold=small_objects_threshold,\n",
    "        min_distance=min_distance)\n",
    "\n",
    "    y_pred.append(mask[0])\n",
    "\n",
    "y_pred = np.stack(y_pred, axis=0)\n",
    "y_pred = np.expand_dims(y_pred, axis=-1)\n",
    "y_true = y_test.copy()\n",
    "\n",
    "m = Metrics('DeepWatershed', seg=False)\n",
    "m.calc_object_stats(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
