{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "This notebook is part of the `deepcell-tf` documentation: https://deepcell.readthedocs.io/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "# Nuclear segmentation and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import imageio\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from deepcell.applications import NuclearSegmentation, CellTracking\n",
    "from deepcell_tracking.trk_io import load_trks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shuffle_colors(ymax, cmap):\n",
    "    \"\"\"Utility function to generate a colormap for a labeled image\"\"\"\n",
    "    cmap = mpl.colormaps[cmap].resampled(ymax)\n",
    "    nmap = cmap(range(ymax))\n",
    "    np.random.shuffle(nmap)\n",
    "    cmap = ListedColormap(nmap)\n",
    "    cmap.set_bad('black')\n",
    "    return cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare nuclear data\n",
    "\n",
    "Sample tracking data can be downloaded from https://datasets.deepcell.org/. Please adjust the path below to where your data is stored locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 71, 584, 600, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_trks('/notebooks/val.trks') # Change this path\n",
    "data['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['X'][0]\n",
    "y = data['y'][0]\n",
    "\n",
    "# Determine position of zero padding for removal\n",
    "# Calculate position of padding based on first frame\n",
    "# Assume that padding is in blocks on the edges of image\n",
    "good_rows = np.where(x[0].any(axis=0))[0]\n",
    "good_cols = np.where(x[0].any(axis=1))[0]\n",
    "slc = (\n",
    "    slice(None),\n",
    "    slice(good_cols[0], good_cols[-1] + 1),\n",
    "    slice(good_rows[0], good_rows[-1] + 1),\n",
    "    slice(None)\n",
    ")\n",
    "x = x[slc]\n",
    "\n",
    "# Determine which frames are zero padding\n",
    "frames = np.sum(y, axis=(1,2)) \n",
    "good_frames = np.where(frames)[0] # True if image not blank\n",
    "x = x[:len(good_frames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(im):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(im, 'Greys_r')\n",
    "    plt.axis('off')\n",
    "    plt.title('Raw Image Data')\n",
    "\n",
    "    fig.canvas.draw()  # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image\n",
    "\n",
    "imageio.mimsave('raw.gif', [plot(x[i, ..., 0]) for i in range(x.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### View .GIF of raw cells\n",
    "\n",
    "![Raw Gif](./raw.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Nuclear Segmentation\n",
    "\n",
    "### Initialize nuclear model\n",
    "\n",
    "The application will download pretrained weights for nuclear segmentation. For more information about application objects, please see our [documentation](https://deepcell.readthedocs.io/en/master/API/deepcell.applications.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 23:42:33.286298: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 23:42:33.951331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10415 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:06:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "app = NuclearSegmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Use the application to generate labeled images\n",
    "\n",
    "Typically, neural networks perform best on test data that is similar to the training data. In the realm of biological imaging, the most common difference between datasets is the resolution of the data measured in microns per pixel. The training resolution of the model can be identified using `app.model_mpp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resolution: 0.65 microns per pixel\n"
     ]
    }
   ],
   "source": [
    "print('Training Resolution:', app.model_mpp, 'microns per pixel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "The resolution of the input data can be specified in `app.predict` using the `image_mpp` option. The `Application` will rescale the input data to match the training resolution and then rescale to the original size before returning the labeled image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 23:43:38.584782: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 540, 540, 1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = app.predict(x, image_mpp=0.65)\n",
    "\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Save labeled images as a gif to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax = np.max(y_pred)\n",
    "cmap = shuffle_colors(ymax, 'tab20')\n",
    "\n",
    "def plot(x, y):\n",
    "    yy = copy.deepcopy(y)\n",
    "    yy = np.ma.masked_equal(yy, 0)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(x, cmap='Greys_r')\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Raw')\n",
    "    ax[1].imshow(yy, cmap=cmap, vmax=ymax)\n",
    "    ax[1].set_title('Segmented')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    fig.canvas.draw()  # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image\n",
    "\n",
    "imageio.mimsave(\n",
    "    './labeled.gif',\n",
    "    [plot(x[i,...,0], y_pred[i,...,0])\n",
    "     for i in range(y_pred.shape[0])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### View .GIF of segmented cells\n",
    "\n",
    "The `NuclearSegmentation` application was able to create a label mask for every cell in every frame!\n",
    "\n",
    "![Segmented GIF](./labeled.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext",
    "tags": []
   },
   "source": [
    "## Cell Tracking\n",
    "\n",
    "The `NuclearSegmentation` worked well, but the cell labels of the same cell are not preserved across frames. To resolve this problem, we can use the `CellTracker`! This object will use another `CellTrackingModel` to compare all cells and determine which cells are the same across frames, as well as if a cell split into daughter cells.\n",
    "\n",
    "### Initalize CellTracking application\n",
    "\n",
    "Create an instance of `deepcell.applications.CellTracking`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearTrackingNE-7.tar.gz\n",
      "786432/781585 [==============================] - 0s 0us/step\n",
      "794624/781585 [==============================] - 0s 0us/step\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/saved-models/NuclearTrackingInf-7.tar.gz\n",
      "540672/539028 [==============================] - 0s 0us/step\n",
      "548864/539028 [==============================] - 0s 0us/step\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "tracker = CellTracking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Track the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 99 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc413a32160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 99 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc413a32160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 100 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc413a32160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 100 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc413a32160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "tracked_data = tracker.track(x, y_pred)\n",
    "y_tracked = tracked_data['y_tracked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Visualize tracking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ymax = np.max(y_tracked)\n",
    "cmap = shuffle_colors(ymax, 'tab20')\n",
    "\n",
    "def plot(x, y):\n",
    "    yy = copy.deepcopy(y)\n",
    "    yy = np.ma.masked_equal(yy, 0)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(x, cmap='Greys_r')\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Raw')\n",
    "    ax[1].imshow(yy, cmap=cmap, vmax=ymax)\n",
    "    ax[1].set_title('Tracked')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    fig.canvas.draw()  # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image\n",
    "\n",
    "imageio.mimsave(\n",
    "    './tracks.gif',\n",
    "    [plot(x[i,...,0], y_tracked[i,...,0])\n",
    "     for i in range(y_tracked.shape[0])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View .GIF of tracked cells\n",
    "\n",
    "Now that we've finished using `CellTracker.track_cells`, not only do the annotations preserve label across frames, but the lineage information has been saved in `CellTracker.tracks`.\n",
    "\n",
    "![Tracked Cells GIF](./tracks.gif)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
