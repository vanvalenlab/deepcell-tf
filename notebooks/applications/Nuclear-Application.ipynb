{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "This notebook is part of the `deepcell-tf` documentation: https://deepcell.readthedocs.io/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "# Nuclear segmentation and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Prepare nuclear data\n",
    "\n",
    "Use `imageio` to load each frame of a gif to form a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepcell-data.s3.amazonaws.com/tracked/HeLa_S3.trks\n",
      "6370648064/6370641920 [==============================] - 144s 0us/step\n",
      "X_train shape: (144, 40, 216, 256, 1)\n",
      "X_test shape: (36, 40, 216, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "from deepcell.datasets.tracked import hela_s3\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = hela_s3.load_tracked_data(seed=0)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train[56]  # chosen batch with divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(im):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.title('Raw Image Data')\n",
    "\n",
    "    fig.canvas.draw()  # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image\n",
    "\n",
    "imageio.mimsave('raw.gif', [plot(x[i, ..., 0]) for i in range(x.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View .GIF of raw cells\n",
    "\n",
    "![Raw Gif](./raw.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Nuclear Segmentation\n",
    "\n",
    "### Initialize nuclear model\n",
    "\n",
    "The application will download pretrained weights for nuclear segmentation. For more information about application objects, please see our [documentation](https://deepcell.readthedocs.io/en/master/API/deepcell.applications.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1026 23:19:46.645289 139723356313408 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 6s 0us/step\n",
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/model-weights/nuclear_0_82800_resnet50_watershed_named_076bb10d832089b6a77faed1e63ad375.h5\n",
      "101310464/101306776 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from deepcell.applications import NuclearSegmentation\n",
    "\n",
    "app = NuclearSegmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Use the application to generate labeled images\n",
    "\n",
    "Typically, neural networks perform best on test data that is similar to the training data. In the realm of biological imaging, the most common difference between datasets is the resolution of the data measured in microns per pixel. The training resolution of the model can be identified using `app.model_mpp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resolution: 0.65 microns per pixel\n"
     ]
    }
   ],
   "source": [
    "print('Training Resolution:', app.model_mpp, 'microns per pixel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "The resolution of the input data can be specified in `app.predict` using the `image_mpp` option. The `Application` will rescale the input data to match the training resolution and then rescale to the original size before returning the labeled image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 216, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = app.predict(x, image_mpp=.75)\n",
    "\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Save labeled images as a gif to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(im1, im2, vmin, vmax):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(im1)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Raw')\n",
    "    ax[1].imshow(im2, cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    ax[1].set_title('Segmented')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    fig.canvas.draw()  # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image\n",
    "\n",
    "imageio.mimsave(\n",
    "    './labeled.gif',\n",
    "    [plot(x[i,...,0], y_pred[i,...,0], y_pred.min(), y_pred.max())\n",
    "     for i in range(y_pred.shape[0])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View .GIF of segmented cells\n",
    "\n",
    "The `NuclearSegmentation` application was able to create a label mask for every cell in every frame!\n",
    "\n",
    "![Segmented GIF](./labeled.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Cell Tracking\n",
    "\n",
    "The `NuclearSegmentation` worked well, but the cell labels of the same cell are not preserved across frames. To resolve this problem, we can use the `CellTracker`! This object will use another `CellTrackingModel` to compare all cells and determine which cells are the same across frames, as well as if a cell split into daughter cells.\n",
    "\n",
    "### Initalize CellTracking application\n",
    "\n",
    "Create an instance of `deepcell.applications.CellTracking`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/model-weights/tracking_model_benchmarking_757_step5_20epoch_80split_9tl.h5\n",
      "2269184/2267544 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from deepcell.applications import CellTracking\n",
    "\n",
    "tracker = CellTracking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/deepcell_tracking/tracking.py:721: FutureWarning: The coordinates keyword argument to skimage.measure.regionprops is deprecated. All features are now computed in rc (row-column) coordinates. Please remove `coordinates=\"rc\"` from all calls to regionprops before updating scikit-image.\n",
      "  props = regionprops(np.squeeze(roi), coordinates='rc')[0]\n",
      "/usr/local/lib/python3.6/dist-packages/deepcell_tracking/tracking.py:685: FutureWarning: The coordinates keyword argument to skimage.measure.regionprops is deprecated. All features are now computed in rc (row-column) coordinates. Please remove `coordinates=\"rc\"` from all calls to regionprops before updating scikit-image.\n",
      "  props = regionprops(np.squeeze(roi), coordinates='rc')\n"
     ]
    }
   ],
   "source": [
    "tracked_data = tracker.track(np.copy(x), y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Visualize tracking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tracking results to a dictionary\n",
    "\n",
    "X = tracked_data['X']  # raw X data\n",
    "y = tracked_data['y_tracked']  # tracked y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(im1,im2,vmin,vmax):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(im1)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Raw')\n",
    "    ax[1].imshow(im2, cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    ax[1].set_title('Tracked')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    fig.canvas.draw()  # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image\n",
    "\n",
    "imageio.mimsave('tracks.gif', [plot(X[i,...,0], y[i,...,0], y.min(), y.max())\n",
    "                               for i in range(y_pred.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View .GIF of tracked cells\n",
    "\n",
    "Now that we've finished using `CellTracker.track_cells`, not only do the annotations preserve label across frames, but the lineage information has been saved in `CellTracker.tracks`.\n",
    "\n",
    "![Tracked Cells GIF](./tracks.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
