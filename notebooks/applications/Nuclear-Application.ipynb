{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "This notebook is part of the `deepcell-tf` documentation: https://deepcell.readthedocs.io/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "# Nuclear segmentation and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Prepare nuclear data\n",
    "\n",
    "Use `imageio` to load each frame of a gif to form a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://deepcell-data.s3.amazonaws.com/tracked/HeLa_S3.trks\n",
      "6370648064/6370641920 [==============================] - 225s 0us/step\n",
      "X_train shape: (144, 40, 216, 256, 1)\n",
      "X_test shape: (36, 40, 216, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "from deepcell.datasets.tracked import hela_s3\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = hela_s3.load_tracked_data(seed=0)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 40, 216, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train[56]  # chosen batch with divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(im):\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.title('Raw Image Data')\n",
    "\n",
    "    fig.canvas.draw()  # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image\n",
    "\n",
    "imageio.mimsave('raw.gif', [plot(x[i, ..., 0]) for i in range(x.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View .GIF of raw cells\n",
    "\n",
    "![Raw Gif](./raw.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Nuclear Segmentation\n",
    "\n",
    "### Initialize nuclear model\n",
    "\n",
    "The application will download pretrained weights for nuclear segmentation. For more information about application objects, please see our [documentation](https://deepcell.readthedocs.io/en/master/API/deepcell.applications.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 5s 0us/step\n",
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/model-weights/nuclear_0_82800_resnet50_watershed_named_076bb10d832089b6a77faed1e63ad375.h5\n",
      "101310464/101306776 [==============================] - 30s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from deepcell.applications import NuclearSegmentation\n",
    "\n",
    "app = NuclearSegmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Use the application to generate labeled images\n",
    "\n",
    "Typically, neural networks perform best on test data that is similar to the training data. In the realm of biological imaging, the most common difference between datasets is the resolution of the data measured in microns per pixel. The training resolution of the model can be identified using `app.model_mpp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resolution: 0.65 microns per pixel\n"
     ]
    }
   ],
   "source": [
    "print('Training Resolution:', app.model_mpp, 'microns per pixel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "The resolution of the input data can be specified in `app.predict` using the `image_mpp` option. The `Application` will rescale the input data to match the training resolution and then rescale to the original size before returning the labeled image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 216, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = app.predict(x, image_mpp=0.65)\n",
    "\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Save labeled images as a gif to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(im1, im2, vmin, vmax):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(im1)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Raw')\n",
    "    ax[1].imshow(im2, cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    ax[1].set_title('Segmented')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    fig.canvas.draw()  # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image\n",
    "\n",
    "imageio.mimsave(\n",
    "    './labeled.gif',\n",
    "    [plot(x[i,...,0], y_pred[i,...,0], y_pred.min(), y_pred.max())\n",
    "     for i in range(y_pred.shape[0])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View .GIF of segmented cells\n",
    "\n",
    "The `NuclearSegmentation` application was able to create a label mask for every cell in every frame!\n",
    "\n",
    "![Segmented GIF](./labeled.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Cell Tracking\n",
    "\n",
    "The `NuclearSegmentation` worked well, but the cell labels of the same cell are not preserved across frames. To resolve this problem, we can use the `CellTracker`! This object will use another `CellTrackingModel` to compare all cells and determine which cells are the same across frames, as well as if a cell split into daughter cells.\n",
    "\n",
    "### Normalize raw data to prepare for tracking\n",
    "\n",
    "The `CellTracker` expects input image data to be zero-mean and unit-variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell_toolbox.processing import normalize\n",
    "\n",
    "x = x.astype('float32')\n",
    "x_norm = np.empty(x.shape)\n",
    "\n",
    "for frame in range(x.shape[0]):\n",
    "    normalized = normalize(x[frame, ..., 0])\n",
    "    x_norm[frame] = np.expand_dims(normalized, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Initalize tracking model\n",
    "\n",
    "Create an instance of `deepcell.applications.CellTrackingModel` and pass the model to the `CellTracker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepcell-data.s3-us-west-1.amazonaws.com/model-weights/tracking_model_benchmarking_757_step5_20epoch_80split_9tl.h5\n",
      "2269184/2267544 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from deepcell.applications import CellTrackingModel\n",
    "from deepcell_tracking import CellTracker\n",
    "\n",
    "tracking_model = CellTrackingModel()\n",
    "\n",
    "cell_tracker = CellTracker(\n",
    "    x_norm, y_pred, tracking_model,\n",
    "    birth=0.99, death=0.99, division=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/deepcell_tracking/tracking.py:721: FutureWarning: The coordinates keyword argument to skimage.measure.regionprops is deprecated. All features are now computed in rc (row-column) coordinates. Please remove `coordinates=\"rc\"` from all calls to regionprops before updating scikit-image.\n",
      "  props = regionprops(np.squeeze(roi), coordinates='rc')[0]\n",
      "/usr/local/lib/python3.6/dist-packages/deepcell_tracking/tracking.py:685: FutureWarning: The coordinates keyword argument to skimage.measure.regionprops is deprecated. All features are now computed in rc (row-column) coordinates. Please remove `coordinates=\"rc\"` from all calls to regionprops before updating scikit-image.\n",
      "  props = regionprops(np.squeeze(roi), coordinates='rc')\n"
     ]
    }
   ],
   "source": [
    "cell_tracker.track_cells()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Visualize tracking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tracking results to a dictionary\n",
    "data = cell_tracker._track_review_dict()\n",
    "\n",
    "X = data['X']  # raw X data\n",
    "y = data['y_tracked']  # tracked y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(im1,im2,vmin,vmax):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(im1)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Raw')\n",
    "    ax[1].imshow(im2, cmap='jet', vmin=vmin, vmax=vmax)\n",
    "    ax[1].set_title('Tracked')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    fig.canvas.draw()  # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image\n",
    "\n",
    "imageio.mimsave('tracks.gif', [plot(X[i,...,0], y[i,...,0], y.min(), y.max())\n",
    "                               for i in range(y_pred.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View .GIF of tracked cells\n",
    "\n",
    "Now that we've finished using `CellTracker.track_cells`, not only do the annotations preserve label across frames, but the lineage information has been saved in `CellTracker.tracks`.\n",
    "\n",
    "![Tracked Cells GIF](./tracks.gif)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
