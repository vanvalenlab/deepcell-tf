{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "This notebook is part of the `deepcell-tf` documentation: https://deepcell.readthedocs.io/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "# Training a cell tracking model\n",
    "\n",
    "Implementation of: [Accurate cell tracking and lineage construction in live-cell imaging experiments with deep learning](https://www.biorxiv.org/content/10.1101/803205v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import errno\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Load the data\n",
    "\n",
    "### Download the data from `deepcell.datasets`\n",
    "\n",
    "`deepcell.datasets` provides access to a set of annotated live-cell imaging datasets which can be used for training cell segmentation and tracking models.\n",
    "All dataset objects share the `load_data()` method, which allows the user to specify the name of the file (`path`), the fraction of data reserved for testing (`test_size`) and a `seed` which is used to generate the random train-test split.\n",
    "Metadata associated with the dataset can be accessed through the `metadata` attribute.\n",
    "\n",
    "Tracked data are stored as `.trks` files. `.trks` files are a special format that includes image and lineage data in `np.arrays`. To access `.trks` files, use `deepcell.utils.tracking_utils.load_trks` and `deepcell.utils.tracking_utils.save_trks`. \n",
    "\n",
    "Training a tracking algorithm is a complicated process that requires alot of data. We recommend combining multiple data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepcell-data.s3.amazonaws.com/tracked/3T3_NIH.trks\n",
      "3229646848/3229644800 [==============================] - 157s 0us/step\n",
      "3T3 -\n",
      "X.shape: (192, 30, 154, 182, 1)\n",
      "y.shape: (192, 30, 154, 182, 1)\n",
      "Downloading data from https://deepcell-data.s3.amazonaws.com/tracked/HeLa_S3.trks\n",
      "6370648064/6370641920 [==============================] - 280s 0us/step\n",
      "HeLa -\n",
      "X.shape: (144, 40, 216, 256, 1)\n",
      "y.shape: (144, 40, 216, 256, 1)\n",
      "Downloading data from https://deepcell-data.s3.amazonaws.com/tracked/HEK293.trks\n",
      "1344610304/1344604160 [==============================] - 70s 0us/step\n",
      "HEK293 -\n",
      "X.shape: (207, 30, 135, 160, 1)\n",
      "y.shape: (207, 30, 135, 160, 1)\n",
      "Downloading data from https://deepcell-data.s3.amazonaws.com/tracked/RAW2647.trks\n",
      "2164695040/2164695040 [==============================] - 204s 0us/step\n",
      "RAW264.7 -\n",
      "X.shape: (99, 30, 202, 240, 1)\n",
      "y.shape: (99, 30, 202, 240, 1)\n"
     ]
    }
   ],
   "source": [
    "# Download four different sets of data (saves to ~/.keras/datasets)\n",
    "filename_3T3 = '3T3_NIH.trks'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.tracked.nih_3t3.load_tracked_data(filename_3T3)\n",
    "print('3T3 -\\nX.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))\n",
    "\n",
    "filename_HeLa = 'HeLa_S3.trks'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.tracked.hela_s3.load_tracked_data(filename_HeLa)\n",
    "print('HeLa -\\nX.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))\n",
    "\n",
    "filename_HEK = 'HEK293.trks'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.tracked.hek293.load_tracked_data(filename_HEK)\n",
    "print('HEK293 -\\nX.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))\n",
    "\n",
    "filename_RAW = 'RAW2647.trks'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.tracked.raw2647.load_tracked_data(filename_RAW)\n",
    "print('RAW264.7 -\\nX.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Preprocess the data\n",
    "\n",
    "After downloading data from `deepcell.datasets.tracked`, we will compile the data into a single dataset. Neural networks require all the input data to be the same dimensions, so we will identify the maximum dimensions and pad smaller datasets to match the maximum dimensions. Neural networks also prefer 0-mean and unit-variance data, so each image will be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from deepcell.utils.tracking_utils import save_trks\n",
    "\n",
    "# Define a normalizaiton function for the raw images that can be run before padding\n",
    "def image_norm(original_image):\n",
    "    # NNs prefer input data that is 0 mean and unit variance\n",
    "    normed_image = (original_image - np.mean(original_image)) / np.std(original_image)\n",
    "    return normed_image\n",
    "\n",
    "# Define all the trks to load\n",
    "basepath = os.path.expanduser(os.path.join('~', '.keras', 'datasets'))\n",
    "trks_files = [os.path.join(basepath, filename_3T3), \n",
    "              os.path.join(basepath, filename_HeLa), \n",
    "              os.path.join(basepath, filename_HEK),\n",
    "              os.path.join(basepath, filename_RAW)]\n",
    "\n",
    "# Each TRKS file may have differrent dimensions,\n",
    "# but the model expects uniform dimensions.\n",
    "# Determine max dimensions and zero pad as neccesary.\n",
    "max_frames = 1\n",
    "max_y = 1\n",
    "max_x = 1\n",
    "\n",
    "for trks_file in trks_files:\n",
    "    trks = load_trks(trks_file)\n",
    "\n",
    "    # Store dimensions of raw and tracked\n",
    "    # to check new data against to pad if neccesary\n",
    "    if trks['X'][0].shape[0] > max_frames:\n",
    "        max_frames = trks['X'][0].shape[0]\n",
    "    if trks['X'][0].shape[1] > max_y:\n",
    "        max_y = trks['X'][0].shape[1]\n",
    "    if trks['X'][0].shape[2] > max_x:\n",
    "        max_x = trks['X'][0].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each trks file, normalize and pad as neccesary\n",
    "lineages = []\n",
    "X = []\n",
    "y = []        \n",
    "\n",
    "k = 0\n",
    "movie_counter = 0\n",
    "for trks_file in trks_files:\n",
    "    trks = load_trks(trks_file)\n",
    "    for i, (lineage, raw, tracked) in enumerate(zip(trks['lineages'], trks['X'], trks['y'])):\n",
    "        movie_counter = k + i\n",
    "\n",
    "        # Normalize the raw images\n",
    "        for frame in range(raw.shape[0]):\n",
    "            raw[frame, :, :, 0] = image_norm(raw[frame, :, :, 0]) \n",
    "            \n",
    "        # Image padding if neccesary - This assumes that raw and tracked have the same shape\n",
    "        if raw.shape[1] < max_y:\n",
    "            diff2pad = max_y - raw.shape[1]\n",
    "            pad_width = int(diff2pad / 2)\n",
    "            if diff2pad % 2 == 0:\n",
    "                # Pad width can be split evenly\n",
    "                raw = np.pad(raw, ((0,0), (pad_width,pad_width), (0,0), (0,0)), mode='constant', constant_values=0)\n",
    "                tracked = np.pad(tracked, ((0,0), (pad_width,pad_width), (0,0), (0,0)), mode='constant', constant_values=0)\n",
    "            else:\n",
    "                # Pad width cannot be split evenly\n",
    "                raw = np.pad(raw, ((0,0), (pad_width + 1, pad_width), (0,0), (0,0)), mode='constant', constant_values=0)\n",
    "                tracked = np.pad(tracked, ((0,0), (pad_width + 1, pad_width), (0,0), (0,0)), mode='constant', constant_values=0)\n",
    "\n",
    "        if raw.shape[2] < max_x:\n",
    "            diff2pad = max_x - raw.shape[2]\n",
    "            pad_width = int(diff2pad / 2)\n",
    "            if diff2pad % 2 == 0:\n",
    "                # Pad width can be split evenly\n",
    "                raw = np.pad(raw, ((0,0), (0,0), (pad_width,pad_width), (0,0)), mode='constant', constant_values=0)\n",
    "                tracked = np.pad(tracked, ((0,0), (0,0), (pad_width,pad_width), (0,0)), mode='constant', constant_values=0)\n",
    "            else:\n",
    "                # Pad width cannot be split evenly\n",
    "                raw = np.pad(raw, ((0,0), (0,0), (pad_width+1,pad_width), (0,0)), mode='constant', constant_values=0)\n",
    "                tracked = np.pad(tracked, ((0,0), (0,0), (pad_width+1,pad_width), (0,0)), mode='constant', constant_values=0)\n",
    "        \n",
    "        if raw.shape[0] < max_frames:   \n",
    "            pad_width = int(max_frames-raw.shape[0])\n",
    "            raw = np.pad(raw, ((0,pad_width), (0,0), (0,0), (0,0)), mode='constant', constant_values=0)\n",
    "            tracked = np.pad(tracked, ((0,pad_width), (0,0), (0,0), (0,0)), mode='constant', constant_values=0)\n",
    "        \n",
    "        lineages.append(lineage)\n",
    "        X.append(raw)\n",
    "        y.append(tracked)\n",
    "                \n",
    "    k = movie_counter + 1\n",
    "\n",
    "# Save the combined datasets into one trks file\n",
    "filename = 'combined_data.trks'\n",
    "save_trks(os.path.join(basepath, filename), lineages, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Describe the data\n",
    "\n",
    "Finally, we can view descriptive statistics on the complete dataset using `deepcell.utils.tracking_utils.trks_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: \n",
      "Image data shape:  (803, 40, 216, 256, 1)\n",
      "Number of lineages (should equal batch size):  803\n",
      "Total number of unique tracks (cells)      -  12697\n",
      "Total number of divisions                  -  944\n",
      "Average cell density (cells/100 sq pixels) -  0.017033540852301552\n",
      "Average number of frames per track         -  25\n"
     ]
    }
   ],
   "source": [
    "# View stats on this combined file\n",
    "from deepcell.utils.tracking_utils import trks_stats\n",
    "trks_stats(os.path.join(basepath, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training data\n",
    "\n",
    "Randomly select a portion of the data to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics: \n",
      "Image data shape:  (722, 40, 216, 256, 1)\n",
      "Number of lineages (should equal batch size):  722\n",
      "Total number of unique tracks (cells)      -  11510\n",
      "Total number of divisions                  -  844\n",
      "Average cell density (cells/100 sq pixels) -  0.017189596498441827\n",
      "Average number of frames per track         -  25\n"
     ]
    }
   ],
   "source": [
    "# combined_data.trks contains all of the data available\n",
    "\n",
    "# To hold out a portion of this data for testing we will establish a random seed\n",
    "test_seed = 1\n",
    "\n",
    "# And how much of the data to hold out\n",
    "test_size = .1\n",
    "\n",
    "# Get the full dataset\n",
    "trks = load_trks(os.path.join(basepath, filename))\n",
    "total_data_size = trks['X'].shape[0]\n",
    "\n",
    "# Select a portion of this dataset randomly \n",
    "import random\n",
    "random.seed(test_seed)\n",
    "train_data_range = int(total_data_size * (1 - test_size))\n",
    "\n",
    "idx_train = random.sample(range(total_data_size), train_data_range)\n",
    "\n",
    "lineages, X, y = [], [], []\n",
    "for i in idx_train:\n",
    "    lineages.append(trks['lineages'][i])\n",
    "    X.append(trks['X'][i])\n",
    "    y.append(trks['y'][i])       \n",
    "\n",
    "# Resave the portion we wish to use as the training (and validation) dataset\n",
    "filename_train = 'combined_training_data.trks'\n",
    "save_trks(os.path.join(basepath, filename_train), lineages, X, y)\n",
    "\n",
    "# View stats on this combined file\n",
    "trks_stats(os.path.join(basepath, filename_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Set up file path constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the data file is currently required for `train_model_()` functions\n",
    "\n",
    "# Change DATA_DIR if you are not using `deepcell.datasets`\n",
    "DATA_DIR = os.path.expanduser(os.path.join('~', '.keras', 'datasets'))\n",
    "\n",
    "# DATA_FILE should be a trks file (contains 2 np arrays and a lineage dictionary)\n",
    "DATA_FILE = os.path.join(DATA_DIR, filename_train)\n",
    "\n",
    "# confirm the data file is available\n",
    "assert os.path.isfile(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up other required filepaths\n",
    "\n",
    "# If the data file is in a subdirectory, mirror it in MODEL_DIR and LOG_DIR\n",
    "PREFIX = os.path.relpath(os.path.dirname(DATA_FILE), DATA_DIR)\n",
    "\n",
    "ROOT_DIR = '/data'  # TODO: Change this! Usually a mounted volume\n",
    "MODEL_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'models', PREFIX))\n",
    "LOG_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'logs', PREFIX))\n",
    "\n",
    "# create directories if they do not exist\n",
    "for d in (MODEL_DIR, LOG_DIR):\n",
    "    try:\n",
    "        os.makedirs(d)\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Training a New Model\n",
    "\n",
    "### Set up training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "n_epoch = 10     # Number of training epochs\n",
    "test_size = .20  # % of data saved as validation\n",
    "train_seed = 1   # Random seed for training/validation data split\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# Tracking training settings\n",
    "features = {'appearance', 'distance', 'neighborhood', 'regionprop'}\n",
    "min_track_length = 9\n",
    "neighborhood_scale_size = 30\n",
    "batch_size = 128  \n",
    "crop_dim = 32\n",
    "in_shape = (crop_dim, crop_dim, 1)\n",
    "\n",
    "model_name = 'tracking_model_seed{}_tl{}'.format(train_seed, min_track_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepcell.image_generators as generators\n",
    "from deepcell.utils.data_utils import get_data\n",
    "\n",
    "# Get the data\n",
    "train_dict, test_dict = get_data(DATA_FILE, mode='siamese_daughters',\n",
    "                                 seed=train_seed, test_size=test_size)\n",
    "\n",
    "# Build the generators and iterators\n",
    "datagen_train = generators.SiameseDataGenerator(\n",
    "    rotation_range=180, # randomly rotate images by 0 to rotation_range degrees\n",
    "    shear_range=0,      # randomly shear images in the range (radians , -shear_range to shear_range)\n",
    "    horizontal_flip=1,  # randomly flip images\n",
    "    vertical_flip=1)    # randomly flip images\n",
    "\n",
    "train_data = datagen_train.flow(\n",
    "    test_dict,\n",
    "    batch_size=batch_size,\n",
    "    seed=train_seed,\n",
    "    crop_dim=crop_dim,\n",
    "    neighborhood_scale_size=neighborhood_scale_size,\n",
    "    min_track_length=min_track_length,\n",
    "    features=features)\n",
    "\n",
    "datagen_test = generators.SiameseDataGenerator(\n",
    "    rotation_range=0,  # randomly rotate images by 0 to rotation_range degrees\n",
    "    shear_range=0,     # randomly shear images in the range (radians , -shear_range to shear_range)\n",
    "    horizontal_flip=0, # randomly flip images\n",
    "    vertical_flip=0)   # randomly flip images\n",
    "\n",
    "test_data = datagen_test.flow(\n",
    "    test_dict,\n",
    "    batch_size=batch_size,\n",
    "    seed=train_seed,\n",
    "    crop_dim=crop_dim,\n",
    "    neighborhood_scale_size=neighborhood_scale_size,\n",
    "    min_track_length=min_track_length,\n",
    "    features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Instantiate the tracking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "tracking_model = model_zoo.siamese_model(\n",
    "    input_shape=in_shape,\n",
    "    neighborhood_scale_size=neighborhood_scale_size,\n",
    "    features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import losses\n",
    "\n",
    "n_classes = tracking_model.layers[-1].output_shape[-1]\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    return losses.weighted_categorical_crossentropy(y_true, y_pred,\n",
    "                                                    n_classes=n_classes,\n",
    "                                                    from_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model\n",
    "\n",
    "Before a model must be trained, it must be compiled with the chosen loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "Call `fit_generator` on the compiled model, along with a default set of callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1 GPUs.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "5535/5536 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9831Epoch 1/10\n",
      "1589/5536 [=======>......................] - ETA: 6:17 - loss: 0.0252 - acc: 0.9961\n",
      "Epoch 00001: val_loss improved from inf to 0.02517, saving model to /data/models/tracking_model_seed1_tl9.h5\n",
      "5536/5536 [==============================] - 4476s 808ms/step - loss: 0.0680 - acc: 0.9831 - val_loss: 0.0252 - val_acc: 0.9961\n",
      "Epoch 2/10\n",
      "5535/5536 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9943Epoch 1/10\n",
      "1589/5536 [=======>......................] - ETA: 6:16 - loss: 0.0224 - acc: 0.9972\n",
      "Epoch 00002: val_loss improved from 0.02517 to 0.02242, saving model to /data/models/tracking_model_seed1_tl9.h5\n",
      "5536/5536 [==============================] - 4458s 805ms/step - loss: 0.0370 - acc: 0.9943 - val_loss: 0.0224 - val_acc: 0.9972\n",
      "Epoch 3/10\n",
      "5535/5536 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9959Epoch 1/10\n",
      "1589/5536 [=======>......................] - ETA: 6:21 - loss: 0.0232 - acc: 0.9967\n",
      "Epoch 00003: val_loss did not improve from 0.02242\n",
      "5536/5536 [==============================] - 4456s 805ms/step - loss: 0.0305 - acc: 0.9959 - val_loss: 0.0232 - val_acc: 0.9967\n",
      "Epoch 4/10\n",
      "5535/5536 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9969Epoch 1/10\n",
      "1589/5536 [=======>......................] - ETA: 6:16 - loss: 0.0201 - acc: 0.9980\n",
      "Epoch 00004: val_loss improved from 0.02242 to 0.02006, saving model to /data/models/tracking_model_seed1_tl9.h5\n",
      "5536/5536 [==============================] - 4455s 805ms/step - loss: 0.0266 - acc: 0.9969 - val_loss: 0.0201 - val_acc: 0.9980\n",
      "Epoch 5/10\n",
      "5535/5536 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9969Epoch 1/10\n",
      "1589/5536 [=======>......................] - ETA: 6:06 - loss: 0.0191 - acc: 0.9979\n",
      "Epoch 00005: val_loss improved from 0.02006 to 0.01907, saving model to /data/models/tracking_model_seed1_tl9.h5\n",
      "5536/5536 [==============================] - 4449s 804ms/step - loss: 0.0260 - acc: 0.9969 - val_loss: 0.0191 - val_acc: 0.9979\n",
      "Epoch 6/10\n",
      "5535/5536 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9973Epoch 1/10\n",
      "1589/5536 [=======>......................] - ETA: 6:17 - loss: 0.0234 - acc: 0.9968\n",
      "Epoch 00006: val_loss did not improve from 0.01907\n",
      "5536/5536 [==============================] - 4462s 806ms/step - loss: 0.0263 - acc: 0.9973 - val_loss: 0.0234 - val_acc: 0.9968\n",
      "Epoch 7/10\n",
      "5535/5536 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9977Epoch 1/10\n",
      "1589/5536 [=======>......................] - ETA: 6:14 - loss: 0.0187 - acc: 0.9982\n",
      "Epoch 00007: val_loss improved from 0.01907 to 0.01870, saving model to /data/models/tracking_model_seed1_tl9.h5\n",
      "5536/5536 [==============================] - 4449s 804ms/step - loss: 0.0232 - acc: 0.9977 - val_loss: 0.0187 - val_acc: 0.9982\n",
      "Epoch 8/10\n",
      "5535/5536 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9979Epoch 1/10\n",
      "1589/5536 [=======>......................] - ETA: 6:10 - loss: 0.0170 - acc: 0.9984\n",
      "Epoch 00008: val_loss improved from 0.01870 to 0.01698, saving model to /data/models/tracking_model_seed1_tl9.h5\n",
      "5536/5536 [==============================] - 4452s 804ms/step - loss: 0.0218 - acc: 0.9979 - val_loss: 0.0170 - val_acc: 0.9984\n",
      "Epoch 9/10\n",
      "5535/5536 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9979Epoch 1/10\n",
      "1589/5536 [=======>......................] - ETA: 6:20 - loss: 0.0181 - acc: 0.9982\n",
      "Epoch 00009: val_loss did not improve from 0.01698\n",
      "5536/5536 [==============================] - 4468s 807ms/step - loss: 0.0231 - acc: 0.9979 - val_loss: 0.0181 - val_acc: 0.9982\n",
      "Epoch 10/10\n",
      "5535/5536 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9983Epoch 1/10\n",
      "1589/5536 [=======>......................] - ETA: 6:15 - loss: 0.0150 - acc: 0.9990\n",
      "Epoch 00010: val_loss improved from 0.01698 to 0.01501, saving model to /data/models/tracking_model_seed1_tl9.h5\n",
      "5536/5536 [==============================] - 4456s 805ms/step - loss: 0.0201 - acc: 0.9983 - val_loss: 0.0150 - val_acc: 0.9990\n"
     ]
    }
   ],
   "source": [
    "from deepcell.utils.train_utils import get_callbacks\n",
    "from deepcell.utils.train_utils import count_gpus\n",
    "from deepcell.utils import tracking_utils\n",
    "\n",
    "\n",
    "model_path = os.path.join(MODEL_DIR, '{}.h5'.format(model_name))\n",
    "loss_path = os.path.join(MODEL_DIR, '{}.npz'.format(model_name))\n",
    "\n",
    "num_gpus = count_gpus()\n",
    "\n",
    "print('Training on', num_gpus, 'GPUs.')\n",
    "\n",
    "train_callbacks = get_callbacks(\n",
    "    model_path,\n",
    "    lr_sched=lr_sched,\n",
    "    tensorboard_log_dir=LOG_DIR,\n",
    "    save_weights_only=num_gpus >= 2,\n",
    "    monitor='val_loss',\n",
    "    verbose=1)\n",
    "\n",
    "# rough estimate for steps_per_epoch\n",
    "total_train_pairs = tracking_utils.count_pairs(train_dict['y'], same_probability=5.0)\n",
    "total_test_pairs = tracking_utils.count_pairs(test_dict['y'], same_probability=5.0)\n",
    "\n",
    "# fit the model on the batches generated by datagen.flow()\n",
    "loss_history = tracking_model.fit_generator(\n",
    "    train_data,\n",
    "    steps_per_epoch=total_train_pairs // batch_size,\n",
    "    epochs=n_epoch,\n",
    "    validation_data=test_data,\n",
    "    validation_steps=total_test_pairs // batch_size,\n",
    "    callbacks=train_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Evaluate Model Performance\n",
    "\n",
    "**Requires a Seed Value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........\n",
      "[[40769    38    23]\n",
      " [   18 40452    50]\n",
      " [    0     0 40490]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y = []\n",
    "Y_pred = []\n",
    "\n",
    "for i in range(1,1000):\n",
    "    if i % 100 == 0:\n",
    "        print(\".\", end=\"\")\n",
    "    lst, y_true = next(test_data)\n",
    "    y_true = np.argmax(y_true, axis=-1)\n",
    "    y_pred = np.argmax(tracking_model.predict(lst), axis=-1)\n",
    "    Y.append(y_true)\n",
    "    Y_pred.append(y_pred)\n",
    "    \n",
    "Y = np.concatenate(Y, axis=0)\n",
    "Y_pred = np.concatenate(Y_pred, axis=0)\n",
    "\n",
    "print(\"\")\n",
    "cm = confusion_matrix(Y, Y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy across all three classes:  0.9989412344057781\n",
      "Accuracy for each individual class [Different, Same, Daughter]:  [0.998506   0.99832182 1.        ]\n"
     ]
    }
   ],
   "source": [
    "test_acc = sum(np.array(Y) == np.array(Y_pred)) / len(Y)\n",
    "print('Accuracy across all three classes: ', test_acc)\n",
    "\n",
    "# Normalize the diagonal entries of the confusion matrix\n",
    "cm = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "# Diagonal entries are the accuracies of each class\n",
    "print('Accuracy for each individual class [Different, Same, Daughter]: ', cm.diagonal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "This model is used within an assignment problem framework to track cells through time-lapse sequences and build cell lineages. To see how this works on example data, refer to Part 2 of this notebook series: [Tracking Example with Benchmarking](https://github.com/vanvalenlab/deepcell-tf/blob/master/notebooks/tracking/Tracking%20Example%20with%20Benchmarking.ipynb)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
