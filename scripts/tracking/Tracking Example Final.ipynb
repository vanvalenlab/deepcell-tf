{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Tracking and Lineage Construction in Live-Cell Imaging Data\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import errno\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepcell-data.s3.amazonaws.com/tracked/3T3_NIH.trks\n",
      "3175817216/3175813120 [==============================] - 87s 0us/step\n",
      "X.shape: (188, 30, 154, 182, 1)\n",
      "y.shape: (188, 30, 154, 182, 1)\n"
     ]
    }
   ],
   "source": [
    "# Download the data (saves to ~/.keras/datasets)\n",
    "filename = '3T3_NIH.trks'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.tracked.nih_3t3.load_tracked_data(filename)\n",
    "\n",
    "print('X.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up filepath constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the data file is currently required for `train_model_()` functions\n",
    "\n",
    "# Change DATA_DIR if you are not using `deepcell.datasets`\n",
    "DATA_DIR = os.path.expanduser(os.path.join('~', '.keras', 'datasets'))\n",
    "DATA_DIR = \"/data/npz_data/cells/HEK293/generic/movie/\"                # USE LOCAL DATA INSTEAD\n",
    "\n",
    "# DATA_FILE should be a trks file (contains 2 np arrays and a lineage dictionary)\n",
    "DATA_FILE = os.path.join(DATA_DIR, filename)\n",
    "DATA_FILE = os.path.join(DATA_DIR, '3T3_HeLa_HEK_corrected.trks')      # USE LOCAL DATA INSTEAD\n",
    "\n",
    "# confirm the data file is available\n",
    "assert os.path.isfile(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up other required filepaths\n",
    "\n",
    "# If the data file is in a subdirectory, mirror it in MODEL_DIR and LOG_DIR\n",
    "PREFIX = os.path.relpath(os.path.dirname(DATA_FILE), DATA_DIR)\n",
    "\n",
    "ROOT_DIR = '/data'  # TODO: Change this! Usually a mounted volume\n",
    "MODEL_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'models', PREFIX))\n",
    "LOG_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'logs', PREFIX))\n",
    "\n",
    "# create directories if they do not exist\n",
    "for d in (MODEL_DIR, LOG_DIR):\n",
    "    try:\n",
    "        os.makedirs(d)\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "tracking_model_name = 'tracking_model'\n",
    "\n",
    "n_epoch = 5  # Number of training epochs\n",
    "test_size = .10  # % of data saved as test\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# Tracking training settings\n",
    "features = {'appearance', 'distance', 'neighborhood', 'regionprop'}\n",
    "min_track_length = 5\n",
    "neighborhood_scale_size=30\n",
    "batch_size = 128  \n",
    "\n",
    "in_shape = (32, 32, 1) # Should this be calculated or hardcoded?\n",
    "seed = 100 # To be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "#### Instantiate the tracking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "tracking_model = model_zoo.siamese_model(\n",
    "    input_shape=in_shape,\n",
    "    neighborhood_scale_size=neighborhood_scale_size,\n",
    "    features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Train a new tracking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.training import train_model_siamese_daughter\n",
    "\n",
    "tracking_model = train_model_siamese_daughter(\n",
    "    model=tracking_model,\n",
    "    dataset=DATA_FILE,  # full path to trks file\n",
    "    model_name=tracking_model_name,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    min_track_length=min_track_length,\n",
    "    features=features,\n",
    "    neighborhood_scale_size=neighborhood_scale_size,\n",
    "    n_epoch=n_epoch,\n",
    "    model_dir=MODEL_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    class_weight=None,\n",
    "    seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Load an existing tracking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tracking model\n",
    "MODEL_DIR = '/data/models/'\n",
    "PREFIX = 'cells/HEK293/generic/'\n",
    "\n",
    "# Re-instantiate the model and load weights\n",
    "siamese_weights_file = '2019-01-24_3T3_HeLa_HEK_corrected_[a,d,n,r]_neighs=30_epochs=5_seed=360_trks_0.h5'\n",
    "siamese_weights_file = os.path.join(MODEL_DIR, PREFIX, siamese_weights_file)\n",
    "\n",
    "tracking_model.load_weights(siamese_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Model Accuracy with Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DATA_FILE from above to extract Test Data \n",
    "# Change if you are not using `deepcell.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/measure/_regionprops.py:250: UserWarning: regionprops and image moments (including moments, normalized moments, central moments, and inertia tensor) of 2D images will change from xy coordinates to rc coordinates in version 0.16.\n",
      "See http://scikit-image.org/docs/0.14.x/release_notes_and_installation.html#deprecations for details on how to avoid this message.\n",
      "  warn(XY_TO_RC_DEPRECATION_MESSAGE)\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/measure/_regionprops.py:260: UserWarning: regionprops and image moments (including moments, normalized moments, central moments, and inertia tensor) of 2D images will change from xy coordinates to rc coordinates in version 0.16.\n",
      "See http://scikit-image.org/docs/0.14.x/release_notes_and_installation.html#deprecations for details on how to avoid this message.\n",
      "  warn(XY_TO_RC_DEPRECATION_MESSAGE)\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "import deepcell.image_generators as generators\n",
    "from deepcell.utils.data_utils import get_data\n",
    "\n",
    "train_dict, test_dict = get_data(DATA_FILE, mode='siamese_daughters', seed=seed)\n",
    "\n",
    "datagen_test = generators.SiameseDataGenerator(\n",
    "        rotation_range=0,  # randomly rotate images by 0 to rotation_range degrees\n",
    "        shear_range=0,     # randomly shear images in the range (radians , -shear_range to shear_range)\n",
    "        horizontal_flip=0, # randomly flip images\n",
    "        vertical_flip=0)   # randomly flip images\n",
    "\n",
    "test_iterator = generators.SiameseIterator(test_dict,\n",
    "                                           datagen_test,\n",
    "                                           neighborhood_scale_size=neighborhood_scale_size,\n",
    "                                           min_track_length=min_track_length,\n",
    "                                           features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........."
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10753,     2,     1],\n",
       "       [    4, 10511,     3],\n",
       "       [   98,  3216,  7346]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y = []\n",
    "Y_pred = []\n",
    "for i in range(1,1001):\n",
    "    if i % 100 == 0:\n",
    "        print(\".\", end=\"\")\n",
    "    lst, y_true = next(test_iterator)\n",
    "    y_true = list(map(np.argmax, y_true))\n",
    "    y_pred = list(map(np.argmax, tracking_model.predict(lst)))\n",
    "    Y.extend(y_true)\n",
    "    Y_pred.extend(y_pred)\n",
    "\n",
    "confusion_matrix(Y, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy across all three classes:  0.8959103150247385\n"
     ]
    }
   ],
   "source": [
    "test_acc = sum(np.array(Y) == np.array(Y_pred)) / len(Y)\n",
    "print('Accuracy across all three classes: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Multiple Movies and Generate Track Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DATA_FILE from above for example Test Data \n",
    "# Change if you are not using `deepcell.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Normalize raw images if needed\n",
    "def image_norm(original_image):\n",
    "    # NNs prefer input data that is 0 mean and unit variance\n",
    "    normed_image = (original_image - np.mean(original_image)) / np.std(original_image)\n",
    "    return normed_image\n",
    "\n",
    "for batch in range(test_dict['X'].shape[0]):\n",
    "    for frame in range(test_dict['X'].shape[1]):\n",
    "        test_dict['X'][batch, frame, :, :, 0] = image_norm(test_dict['X'][batch, frame, :, :, 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-4b0afe921308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                          \u001b[0mtrack_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbirth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                          \u001b[0mneighborhood_scale_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                          features=features)\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_track_cells\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.trk'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/deepcell/tracking.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, movie, annotation, model, features, crop_dim, death, birth, division, max_distance, track_length, neighborhood_scale_size, neighborhood_true_size, data_format)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         self.feature_shape = {\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;34m'appearance'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcrop_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             'neighborhood': (2 * neighborhood_scale_size + 1,\n\u001b[1;32m     85\u001b[0m                              2 * neighborhood_scale_size + 1, 1),\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# The tracking model is used in concert with other processes to track cells\n",
    "# Import the neccesary tracking functionality\n",
    "import deepcell.tracking\n",
    "\n",
    "# Define where cell tracks will be saved\n",
    "TRACK_DIR = '/tracking/tracking_movies/'\n",
    "TRACK_FILE_NAME = 'Batch_'\n",
    "\n",
    "# Generate a cell track for each batch\n",
    "#for batch in range(test_dict['X'].shape[0]):\n",
    "for batch in test_dict['X'][0:1]:\n",
    "    trial = deepcell.tracking.cell_tracker([batch], [batch],\n",
    "                         tracking_model,\n",
    "                         max_distance=200,\n",
    "                         track_length=5, division=0.5, birth=0.9, death=0.9,\n",
    "                         neighborhood_scale_size=30,\n",
    "                         features=features)\n",
    "    trial._track_cells()\n",
    "    file_name = base_name + str(batch).zfill(2) + '.trk'\n",
    "    file_path = os.path.join(base_path, file_name)\n",
    "    trial.dump(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax[5].imshow(watershed_images[index, frame, ..., 0], cmap='jet')\n",
    "\n",
    "\n",
    "# Can also export as a video\n",
    "# But this does not render well on GitHub\n",
    "from IPython.display import HTML\n",
    "from deepcell.utils.plot_utils import get_js_video\n",
    "\n",
    "HTML(get_js_video(watershed_images[..., [-1]], batch=index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Raw and Tracked Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0\n",
    "\n",
    "for i in range(45):\n",
    "    #name_raw = os.paHeLa_and_3T3th.join('tracking_movies/test_true2_{:02}_.png'.format(i))\n",
    "    name_tracked = os.path.join('tracking_movies/test_tracked3_{:02}_.png'.format(i))\n",
    "    #plt.imsave(name_raw, test_data['y'][0, i, :, :, channel], cmap='jet')\n",
    "    plt.imsave(name_tracked, trial.y_tracked[i, :, :, channel], cmap='cubehelix', vmin=0, vmax=250)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
