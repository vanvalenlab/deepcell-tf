{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Tracking and Lineage Construction in Live-Cell Imaging Data\n",
    "\n",
    "### Part 2 (of 2)\n",
    "---\n",
    "\n",
    "## Employing the Model to Track Cells and Benchmarking the Results\n",
    "---\n",
    "\n",
    "Implementation of:\n",
    "\n",
    "[Accurate cell tracking and lineage construction in live-cell imaging experiments with deep learning](https://www.biorxiv.org/content/10.1101/803205v2)\n",
    "\n",
    "Deployed at:\n",
    "\n",
    "[DeepCell.org](http://www.deepcell.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import errno\n",
    "import argparse\n",
    "import fnmatch\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skimage.external.tifffile import imsave\n",
    "from skimage.external.tifffile import TiffFile\n",
    "\n",
    "import deepcell\n",
    "from deepcell.utils.misc_utils import sorted_nicely\n",
    "from deepcell.utils.tracking_utils import load_trks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track Multiple Movies with Multiple Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Ground Truth Benchmark Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepcell-data.s3.amazonaws.com/tracking_manuscript_benchmarking/GT_tracks/3T3_NIH_benchmarks.trks\n",
      "322985984/322979840 [==============================] - 14s 0us/step\n",
      "3T3 -\n",
      "X.shape: (19, 30, 154, 182, 1)\n",
      "y.shape: (19, 30, 154, 182, 1)\n",
      "Downloading data from https://deepcell-data.s3.amazonaws.com/tracking_manuscript_benchmarking/GT_tracks/HEK293_generic_benchmarks.trks\n",
      "134987776/134983680 [==============================] - 6s 0us/step\n",
      "HEK293 -\n",
      "X.shape: (20, 30, 135, 160, 1)\n",
      "y.shape: (20, 30, 135, 160, 1)\n",
      "Downloading data from https://deepcell-data.s3.amazonaws.com/tracking_manuscript_benchmarking/GT_tracks/HeLa_S3_benchmarks.trks\n",
      "637083648/637081600 [==============================] - 24s 0us/step\n",
      "HeLa -\n",
      "X.shape: (14, 40, 216, 256, 1)\n",
      "y.shape: (14, 40, 216, 256, 1)\n",
      "Downloading data from https://deepcell-data.s3.amazonaws.com/tracking_manuscript_benchmarking/GT_tracks/RAW2647_generic_benchmarks.trks\n",
      "226959360/226959360 [==============================] - 11s 0us/step\n",
      "RAW264.7 -\n",
      "X.shape: (10, 30, 202, 240, 1)\n",
      "y.shape: (10, 30, 202, 240, 1)\n"
     ]
    }
   ],
   "source": [
    "# Download four different sets of ground truth data (saves to ~/.keras/datasets)\n",
    "# We will re-track this GT data to verify our results\n",
    "\n",
    "filename_3T3 = '3T3_NIH_benchmarks.trks'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.tracked.nih_3t3_bench.load_tracked_data(filename_3T3)\n",
    "print('3T3 -\\nX.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))\n",
    "\n",
    "filename_HEK = 'HEK293_benchmarks.trks'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.tracked.hek293_bench.load_tracked_data(filename_HEK)\n",
    "print('HEK293 -\\nX.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))\n",
    "\n",
    "filename_HeLa = 'HeLa_S3_benchmarks.trks'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.tracked.hela_s3_bench.load_tracked_data(filename_HeLa)\n",
    "print('HeLa -\\nX.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))\n",
    "\n",
    "filename_RAW = 'RAW2647_benchmarks.trks'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.tracked.raw2647_bench.load_tracked_data(filename_RAW)\n",
    "print('RAW264.7 -\\nX.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup File Path Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change DATA_DIR if you are not using `deepcell.datasets`\n",
    "DATA_DIR = os.path.expanduser(os.path.join('~', '.keras', 'datasets'))\n",
    "\n",
    "ROOT_DIR = '/data'  # TODO: Change this! Usually a mounted volume\n",
    "MODEL_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'models'))\n",
    "\n",
    "# Define destination folders for tracked output\n",
    "TRACK_DIRS = [\n",
    "    os.path.abspath(os.path.join(DATA_DIR, 'track_data/3T3')),\n",
    "    os.path.abspath(os.path.join(DATA_DIR, 'track_data/HEK293')),\n",
    "    os.path.abspath(os.path.join(DATA_DIR, 'track_data/HeLa')),\n",
    "    os.path.abspath(os.path.join(DATA_DIR, 'track_data/RAW264.7'))\n",
    "]\n",
    "\n",
    "# create directories if they do not exist\n",
    "for d in TRACK_DIRS + [MODEL_DIR]:\n",
    "    try:\n",
    "        os.makedirs(d)\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data to track (benchmark test files)\n",
    "# Each trks file contains multiple movies (or batches)\n",
    "\n",
    "GT_BASE_DIR = '/data/npz_data/tracking_benchmark_data/test/'\n",
    "\n",
    "GT_trks_files = [\n",
    "    os.path.join(GT_BASE_DIR, '3T3_NIH_test_BData.trks'),\n",
    "    os.path.join(GT_BASE_DIR, 'HEK293_generic_test_BData.trks'),\n",
    "    os.path.join(GT_BASE_DIR, 'HeLa_S3_test_BData.trks'),\n",
    "    os.path.join(GT_BASE_DIR, 'RAW264_generic_test_BData.trks')\n",
    "]\n",
    "\n",
    "assert all(os.path.exists(x) for x in GT_trks_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work Through Each Dataset with Multiple Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import a Tracking Model to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "# Tracking model settings (These settings should mirror those from Part 1)\n",
    "features = {'appearance', 'distance', 'neighborhood', 'regionprop'}\n",
    "\n",
    "min_track_length = 9\n",
    "neighborhood_scale_size = 30\n",
    "batch_size = 128  \n",
    "crop_dim = 32\n",
    "\n",
    "# Re-instantiate the tracking model\n",
    "tracking_model = model_zoo.siamese_model(\n",
    "    input_shape=(crop_dim, crop_dim, 1),\n",
    "    neighborhood_scale_size=neighborhood_scale_size,\n",
    "    features=features)\n",
    "\n",
    "# Load model weights\n",
    "siamese_weights_file = 'tracking_model_seed1_tl9.h5'\n",
    "siamese_weights_file = os.path.join(MODEL_DIR, siamese_weights_file)\n",
    "\n",
    "tracking_model.load_weights(siamese_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Tracking Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Critical Parameters \n",
    "# Key variables are lists to facilitate parameter sweeps if desired\n",
    "\n",
    "# If model prediction for daughter is higher than this parameter,\n",
    "# then daughter assignment made\n",
    "division = [0.9]\n",
    "\n",
    "# Parameter for cost matrix - if other possible assignments are higher than this,\n",
    "# then a birth occurred\n",
    "birth = [0.99]\n",
    "\n",
    "# Parameter for cost matrix - if other possible assignments are higher than this,\n",
    "# then a death occurred\n",
    "death = [0.99]\n",
    "\n",
    "# If two labels are beyond this distance they will not be compared\n",
    "# (smaller distances -> faster tracking)\n",
    "max_distance = 50\n",
    "\n",
    "# Define Parameters that should not be changed\n",
    "# (they are model dependent or training data dependent)\n",
    "track_length = 9\n",
    "neighborhood_scale_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Model Iteratively for the Parameters of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: Dataset 0, Batch 0\n",
      "Tracking: Dataset 0, Batch 1\n",
      "Tracking: Dataset 0, Batch 2\n",
      "Tracking: Dataset 0, Batch 3\n",
      "Tracking: Dataset 0, Batch 4\n",
      "Tracking: Dataset 0, Batch 5\n",
      "Tracking: Dataset 0, Batch 6\n",
      "Tracking: Dataset 0, Batch 7\n",
      "Tracking: Dataset 0, Batch 8\n",
      "Tracking: Dataset 0, Batch 9\n",
      "Tracking: Dataset 0, Batch 10\n",
      "Tracking: Dataset 0, Batch 11\n",
      "Tracking: Dataset 0, Batch 12\n",
      "Tracking: Dataset 0, Batch 13\n",
      "Tracking: Dataset 0, Batch 14\n",
      "Tracking: Dataset 0, Batch 15\n",
      "Tracking: Dataset 0, Batch 16\n",
      "Tracking: Dataset 0, Batch 17\n",
      "Tracking: Dataset 0, Batch 18\n",
      "Tracking: Dataset 0, Batch 19\n",
      "Tracking: Dataset 0, Batch 20\n",
      "Tracking: Dataset 0, Batch 21\n",
      "Tracking: Dataset 0, Batch 22\n",
      "Tracking: Dataset 0, Batch 23\n",
      "Tracking: Dataset 1, Batch 0\n",
      "Tracking: Dataset 1, Batch 1\n",
      "Tracking: Dataset 1, Batch 2\n",
      "Tracking: Dataset 1, Batch 3\n",
      "Tracking: Dataset 1, Batch 4\n",
      "Tracking: Dataset 1, Batch 5\n",
      "Tracking: Dataset 1, Batch 6\n",
      "Tracking: Dataset 1, Batch 7\n",
      "Tracking: Dataset 1, Batch 8\n",
      "Tracking: Dataset 1, Batch 9\n",
      "Tracking: Dataset 1, Batch 10\n",
      "Tracking: Dataset 1, Batch 11\n",
      "Tracking: Dataset 1, Batch 12\n",
      "Tracking: Dataset 1, Batch 13\n",
      "Tracking: Dataset 1, Batch 14\n",
      "Tracking: Dataset 1, Batch 15\n",
      "Tracking: Dataset 1, Batch 16\n",
      "Tracking: Dataset 1, Batch 17\n",
      "Tracking: Dataset 1, Batch 18\n",
      "Tracking: Dataset 1, Batch 19\n",
      "Tracking: Dataset 1, Batch 20\n",
      "Tracking: Dataset 1, Batch 21\n",
      "Tracking: Dataset 1, Batch 22\n",
      "Tracking: Dataset 1, Batch 23\n",
      "Tracking: Dataset 1, Batch 24\n",
      "Tracking: Dataset 1, Batch 25\n",
      "Tracking: Dataset 2, Batch 0\n",
      "Tracking: Dataset 2, Batch 1\n",
      "Tracking: Dataset 2, Batch 2\n",
      "Tracking: Dataset 2, Batch 3\n",
      "Tracking: Dataset 2, Batch 4\n",
      "Tracking: Dataset 2, Batch 5\n",
      "Tracking: Dataset 2, Batch 6\n",
      "Tracking: Dataset 2, Batch 7\n",
      "Tracking: Dataset 2, Batch 8\n",
      "Tracking: Dataset 2, Batch 9\n",
      "Tracking: Dataset 2, Batch 10\n",
      "Tracking: Dataset 2, Batch 11\n",
      "Tracking: Dataset 2, Batch 12\n",
      "Tracking: Dataset 2, Batch 13\n",
      "Tracking: Dataset 2, Batch 14\n",
      "Tracking: Dataset 2, Batch 15\n",
      "Tracking: Dataset 2, Batch 16\n",
      "Tracking: Dataset 2, Batch 17\n",
      "Tracking: Dataset 3, Batch 0\n",
      "Tracking: Dataset 3, Batch 1\n",
      "Tracking: Dataset 3, Batch 2\n",
      "Tracking: Dataset 3, Batch 3\n",
      "Tracking: Dataset 3, Batch 4\n",
      "Tracking: Dataset 3, Batch 5\n",
      "Tracking: Dataset 3, Batch 6\n",
      "Tracking: Dataset 3, Batch 7\n",
      "Tracking: Dataset 3, Batch 8\n",
      "Tracking: Dataset 3, Batch 9\n",
      "Tracking: Dataset 3, Batch 10\n",
      "Tracking: Dataset 3, Batch 11\n",
      "Tracking: Dataset 3, Batch 12\n"
     ]
    }
   ],
   "source": [
    "# The tracking model is used in concert with other processes to track cells\n",
    "# Import the neccesary tracking functionality\n",
    "import deepcell.tracking\n",
    "\n",
    "\n",
    "# The tracker requires normalized images as input\n",
    "def image_norm(img):\n",
    "    return (img - np.mean(img)) / np.std(img)\n",
    "\n",
    "\n",
    "# Go through each Dataset (3T3, HEK293, HeLa, RAW264.7)\n",
    "for set_num, dataset in enumerate(GT_trks_files):\n",
    "    trks = load_trks(dataset)\n",
    "    # Go through each batch (movie) in each dataset\n",
    "    for batch_num, (lineage, raw, tracked) in enumerate(zip(trks['lineages'], trks['X'], trks['y'])):        \n",
    "        # Normalize raw images\n",
    "        for frame in range(raw.shape[0]):\n",
    "            raw[frame, :, :, 0] = image_norm(raw[frame, :, :, 0]) \n",
    "\n",
    "        # Track each movie with each division parameter\n",
    "        print('Tracking: Dataset {}, Batch {}'.format(set_num, batch_num))\n",
    "        for div_param in division:\n",
    "            # For each birth parameter\n",
    "            for birth_param in birth:\n",
    "                # For each death parameter\n",
    "                for death_param in death:\n",
    "                    pass\n",
    "                    # Track with the selected parameters\n",
    "                    trial = deepcell.tracking.cell_tracker(\n",
    "                        raw, tracked, tracking_model,\n",
    "                        max_distance=max_distance,\n",
    "                        track_length=track_length,\n",
    "                        division=div_param,\n",
    "                        birth=birth_param,\n",
    "                        death=death_param,\n",
    "                        neighborhood_scale_size=neighborhood_scale_size,\n",
    "                        features=features)\n",
    "\n",
    "                    trial.track_cells()\n",
    "                    \n",
    "                    # Run FP post processing and save the result in the correct location\n",
    "                    file_name = 'batch_{}_div{}_b{}_d{}'.format(\n",
    "                        str(batch_num).zfill(3),\n",
    "                        str(div_param).zfill(3),\n",
    "                        str(birth_param).zfill(3),\n",
    "                        str(death_param).zfill(3))\n",
    "                    file_path = os.path.join(TRACK_DIRS[set_num], file_name)\n",
    "                    fp_fixed_trk = trial.postprocess(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate the Results Into ISBI Format for Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Cell Lineages in an ISBI-Formatted Output txt\n",
    "\n",
    "The ISBI Cell Tracking Challenge requires a text file (man_track.txt) that represents a batch's cell lineage as an acyclic graph. The format of this file is as follows: Every line corresponds to a single track that is encoded by four numbers separated by a space -  \n",
    "L B E P  \n",
    "where L is a unique label of the track (label of markers, 16-bit positive value),  \n",
    "B is a zero-based index of the frame in which the track begins,  \n",
    "E is a zero-based index of the frame in which the track ends,  \n",
    "P is the label of the parent track (0 is used when no parent is defined)\n",
    "\n",
    "N.B. DeepCell's unique approach allows for cells to be tracked even if it momentarily leaves the frame. This is not possible in convential tracking algorithms, so ISBI considers a cell's track to have ended once it leaves the frame. We adjust the output here to keep with ISBI's formatting (ie. each track only contains contiguous frames)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ISBI Translator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell_tracking.isbi_utils import contig_tracks\n",
    "from deepcell_tracking.isbi_utils import trk_to_isbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Save Location for Benchmark Files (ie: 001, 001_GT, 001_RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where benchmark data will be saved\n",
    "BENCH_DIR = os.path.abspath(os.path.join(DATA_DIR, 'tracking_benchmarks'))\n",
    "\n",
    "# Define where tracks will be saved\n",
    "BENCH_DIRS = [\n",
    "    os.path.join(BENCH_DIR, '3T3'),\n",
    "    os.path.join(BENCH_DIR, 'HEK293'),\n",
    "    os.path.join(BENCH_DIR, 'HeLa'),\n",
    "    os.path.join(BENCH_DIR, 'RAW264.7')\n",
    "]\n",
    "\n",
    "# create directories if they do not exist\n",
    "for d in BENCH_DIRS:\n",
    "    try:\n",
    "        os.makedirs(d)\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate RAW and GT Benchmark Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create benchmark files (ie: 001, 001_GT, etc) from the Ground Truth .trk files\n",
    "\n",
    "from skimage.external.tifffile import imsave\n",
    "\n",
    "for set_num, dataset in enumerate(GT_trks_files):\n",
    "    # Load trks file\n",
    "    trks = load_trks(dataset)\n",
    "    lineages, raw, tracked = trks[\"lineages\"], trks[\"X\"], trks[\"y\"]\n",
    "\n",
    "    # Define Save Location\n",
    "    PARAMS = 'div{}_b{}_d{}'.format(\n",
    "        str(div_param).zfill(3),\n",
    "        str(birth_param).zfill(3),\n",
    "        str(death_param).zfill(3),\n",
    "    )\n",
    "\n",
    "    # Build subdirectories to hold benchmark info           \n",
    "    BENCHMARK_DIR = os.path.abspath(os.path.join(BENCH_DIRS[set_num], PARAMS))\n",
    "    \n",
    "    # First loop through tracks and ensure that all tracks have continuous frames.\n",
    "    for batch, batch_info in enumerate(lineages):\n",
    "\n",
    "        batch_tracked = tracked[batch]\n",
    "        labels = list(batch_info.keys())\n",
    "        max_label = max(labels)\n",
    "\n",
    "        for label in labels:\n",
    "            batch_info, batch_tracked = contig_tracks(label, batch_info, batch_tracked)\n",
    "\n",
    "            if max(batch_info.keys()) > max_label:\n",
    "                # New track was added!\n",
    "                new_max_label = max(batch_info.keys())\n",
    "                labels.append(new_max_label)\n",
    "                max_label = new_max_label\n",
    "\n",
    "        tracked[batch] = batch_tracked  # resave inside original array\n",
    "\n",
    "    # Record lineage data in txt as it is generated\n",
    "    for batch, batch_info in enumerate(lineages):\n",
    "        # Build subdirectories to hold benchmark info\n",
    "        # Build subdirectories to hold benchmark info\n",
    "        B_SUB_DIR_RAW = os.path.join(BENCHMARK_DIR, '{:03}'.format(batch + 1))\n",
    "        B_SUB_DIR_GT = os.path.join(BENCHMARK_DIR, '{:03}_GT'.format(batch + 1))\n",
    "        B_SUB_DIR_SEG = os.path.join(B_SUB_DIR_GT, 'SEG')\n",
    "        B_SUB_DIR_TRA = os.path.join(B_SUB_DIR_GT, 'TRA')\n",
    "\n",
    "        # Create directories if they do not exist\n",
    "        for d in (B_SUB_DIR_RAW, B_SUB_DIR_GT, B_SUB_DIR_SEG, B_SUB_DIR_TRA):\n",
    "            try:\n",
    "                os.makedirs(d)\n",
    "            except OSError as exc:  # Guard against race condition\n",
    "                if exc.errno != errno.EEXIST:\n",
    "                    raise\n",
    "\n",
    "        # Resave the .trk image data with new track values.\n",
    "        channel = 0 # These images should only have one channel\n",
    "        for i in range(raw.shape[1]):\n",
    "            name_raw = os.path.join(B_SUB_DIR_RAW,'t{:03}_.tif'.format(i))\n",
    "            name_tracked_SEG = os.path.join(B_SUB_DIR_SEG,'man_seg{:03}.tif'.format(i))\n",
    "            name_tracked_TRA = os.path.join(B_SUB_DIR_TRA,'man_track{:03}.tif'.format(i))\n",
    "            imsave(name_raw, raw[batch, i, :, :, channel])\n",
    "            imsave(name_tracked_SEG, tracked[batch, i, :, :, channel].astype('uint16'))\n",
    "            imsave(name_tracked_TRA, tracked[batch, i, :, :, channel].astype('uint16'))\n",
    "\n",
    "        # Prepare output txt\n",
    "        filename = os.path.join(B_SUB_DIR_TRA, \"man_track.txt\")\n",
    "        trk_to_isbi(batch_info, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translate Result trk files and Generate Benchmark Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/001_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/002_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/003_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/004_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/005_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/006_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/007_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/008_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/009_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/010_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/011_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/012_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/013_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/014_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/015_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/016_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/017_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/018_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/019_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/020_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/021_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/022_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/023_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/3T3/div0.9_b0.99_d0.99/024_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/001_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/002_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/003_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/004_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/005_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/006_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/007_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/008_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/009_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/010_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/011_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/012_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/013_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/014_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/015_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/016_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/017_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/018_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/019_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/020_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/021_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/022_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/023_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/024_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/025_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HEK293/div0.9_b0.99_d0.99/026_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/001_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/002_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/003_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/004_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/005_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/006_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/007_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/008_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/009_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/010_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/011_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/012_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/013_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/014_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/015_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/016_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/017_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/HeLa/div0.9_b0.99_d0.99/018_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/001_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/002_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/003_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/004_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/005_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/006_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/007_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/008_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/009_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/010_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/011_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/012_RES\n",
      "Files will be saved at:  /root/.keras/datasets/tracking_benchmarks/RAW264.7/div0.9_b0.99_d0.99/013_RES\n"
     ]
    }
   ],
   "source": [
    "## Create new benchmark files (ie: 001_RES) from mutliple .trk files\n",
    "\n",
    "# Go through each Dataset (3T3, HEK293, HeLa, RAW264.7)\n",
    "for set_num, dataset in enumerate(TRACK_DIRS):\n",
    "    # Define Save Location\n",
    "    PARAMS = 'div{}_b{}_d{}'.format(\n",
    "        str(div_param).zfill(3),\n",
    "        str(birth_param).zfill(3),\n",
    "        str(death_param).zfill(3))\n",
    "\n",
    "    # Build subdirectories to hold benchmark info           \n",
    "    BENCHMARK_DIR = os.path.abspath(os.path.join(BENCH_DIRS[set_num], PARAMS))\n",
    "\n",
    "    # Go through each batch (movie) in each dataset\n",
    "    movie_list = sorted_nicely(os.listdir(dataset))\n",
    "    \n",
    "    for batch_num, batch in enumerate(movie_list):\n",
    "        # Load the trk file\n",
    "        trks = load_trks(os.path.join(dataset, batch))\n",
    "        lineages, raw, tracked = trks[\"lineages\"], trks[\"X\"], trks[\"y\"]\n",
    "\n",
    "        B_SUB_DIR = os.path.join(BENCHMARK_DIR, '{:03}_RES'.format(batch_num+1))\n",
    "        print('Files will be saved at: ', B_SUB_DIR)\n",
    "\n",
    "        # create directories if they do not exist\n",
    "        try:\n",
    "            os.makedirs(B_SUB_DIR)\n",
    "        except OSError as exc:  # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "        # Record lineage data in txt as it is generated\n",
    "        batch_info = lineages[0]\n",
    "\n",
    "        # Prepare output txt\n",
    "        batch_tracked = tracked\n",
    "        labels = list(batch_info.keys())\n",
    "        max_label = max(labels)\n",
    "\n",
    "        for label in labels:\n",
    "            batch_info, tracked = contig_tracks(label, batch_info, tracked)\n",
    "\n",
    "            if max(batch_info.keys()) > max_label:\n",
    "                # New track was added!\n",
    "                new_max_label = max(batch_info.keys())\n",
    "                labels.append(new_max_label)\n",
    "                max_label = new_max_label\n",
    "\n",
    "        # Save Image Files\n",
    "        channel = 0 # These images should only have one channel\n",
    "        for i in range(raw.shape[0]):\n",
    "            name_tracked = os.path.join(B_SUB_DIR,'mask{:03}.tif'.format(i))\n",
    "            imsave(name_tracked, tracked[i, :, :, channel].astype('uint16'))\n",
    "\n",
    "        filename = os.path.join(B_SUB_DIR, \"res_track.txt\")\n",
    "        trk_to_isbi(batch_info, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Graph Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Comparison Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.metrics import match_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteratively Compare Each Movie (Tracked with Each Parameter) To the Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell_tracking.isbi_utils import classify_divisions\n",
    "from deepcell_tracking.isbi_utils import txt_to_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.keras/datasets/tracking_benchmarks/3T3\n",
      "missed node 297_12 division completely\n",
      "005\n",
      "missed node 493_25 division completely\n",
      "007\n",
      "missed node 429_5 division completely\n",
      "014\n",
      "missed node 435_2 division completely\n",
      "021\n",
      "missed node 524_13 division completely\n",
      "missed node 601_20 division completely\n",
      "024\n",
      "/root/.keras/datasets/tracking_benchmarks/HEK293\n",
      "846_9 out degree = 2, daughters mismatch, gt and res degree equal.\n",
      "002\n",
      "missed node 843_13 division completely\n",
      "005\n",
      "missed node 732_13 division completely\n",
      "006\n",
      "missed node 1139_25 division completely\n",
      "016\n",
      "missed node 579_2 division completely\n",
      "017\n",
      "831_13 out degree = 1, daughters mismatch.\n",
      "018\n",
      "missed node 955_16 division completely\n",
      "019\n",
      "807_24 out degree = 1, daughters mismatch.\n",
      "023\n",
      "missed node 523_7 division completely\n",
      "024\n",
      "807_15 out degree = 3, daughters mismatch.\n",
      "025\n",
      "missed node 845_2 division completely\n",
      "026\n",
      "/root/.keras/datasets/tracking_benchmarks/HeLa\n",
      "missed node 1304_36 division completely\n",
      "005\n",
      "/root/.keras/datasets/tracking_benchmarks/RAW264.7\n",
      "missed node 1292_17 division completely\n",
      "002\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from deepcell_tracking.utils import clean_up_annotations\n",
    "\n",
    "# Prep a list to hold each dataset's results\n",
    "dataset_cm = []\n",
    "\n",
    "# Go through each Dataset (3T3, HEK293, HeLa, RAW264.7)\n",
    "for ben_trk_folder in BENCH_DIRS:\n",
    "    print(ben_trk_folder)\n",
    "    # Prep a list to hold results for each set of parameters\n",
    "    params_cm = []\n",
    "   \n",
    "    # Go through each parameter combination\n",
    "    for div_param in division:\n",
    "        # For each birth parameter\n",
    "        for birth_param in birth:\n",
    "            # For each death parameter\n",
    "            for death_param in death:  \n",
    "\n",
    "                PARAMS = 'div{}_b{}_d{}'.format(div_param, birth_param, death_param)\n",
    "                BENCHMARK_DIR = os.path.join(ben_trk_folder, PARAMS)\n",
    "\n",
    "                # Compile a list of each movie\n",
    "                sub_dirs = sorted_nicely(os.listdir(BENCHMARK_DIR))\n",
    "                movie_list = fnmatch.filter(sub_dirs, '???')\n",
    "                # Prep a list to hold each movie's results\n",
    "                cm_list = []\n",
    "                # Loop through each set of movies \n",
    "                for name in movie_list:\n",
    "                    # Extract track.txt for each movie\n",
    "                    pattern_gt = os.path.join(BENCHMARK_DIR, name + '_GT/TRA/')\n",
    "                    pattern_res = os.path.join(BENCHMARK_DIR, name + '_RES/')\n",
    "\n",
    "                    # Load gt and clean up to generate unique labels\n",
    "                    gt = np.stack([TiffFile(f).asarray()\n",
    "                                   for f in np.sort(glob.glob(pattern_gt + '*.tif'))])\n",
    "\n",
    "                    res = np.stack([TiffFile(f).asarray()\n",
    "                                    for f in np.sort(glob.glob(pattern_res + '*.tif'))])\n",
    "\n",
    "                    unique = clean_up_annotations(np.copy(gt))\n",
    "\n",
    "                    # Calculate iou matrix for each dataset\n",
    "                    iou_gt = match_nodes(gt, unique)\n",
    "                    iou_res = match_nodes(res, unique)\n",
    "\n",
    "                    thresh = 0.5\n",
    "                    x, y, z = np.where(iou_gt > thresh)\n",
    "                    node_key_gt = {'{}_{}'.format(y[i], x[i]): '{}_{}'.format(z[i], x[i])\n",
    "                                   for i in range(x.shape[0])}\n",
    "\n",
    "                    x, y, z = np.where(iou_res > thresh)\n",
    "                    node_key_res = {'{}_{}'.format(y[i], x[i]): '{}_{}'.format(z[i], x[i])\n",
    "                                    for i in range(x.shape[0])}\n",
    "\n",
    "                    G_res = txt_to_graph(pattern_res + 'res_track.txt')\n",
    "                    G_gt = txt_to_graph(pattern_gt + 'man_track.txt')\n",
    "\n",
    "                    G_res = nx.relabel.relabel_nodes(G_res, node_key_res)\n",
    "                    G_gt = nx.relabel.relabel_nodes(G_gt, node_key_gt)\n",
    "\n",
    "                    stats = classify_divisions(G_gt, G_res)\n",
    "                    if any(stats[k] for k in ('Incorrect division', 'False negative division')):\n",
    "                        print(name)\n",
    "                    cm_list.append(stats)\n",
    "\n",
    "                params_cm.append(cm_list)\n",
    "\n",
    "    dataset_cm.append(params_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tally up all the statistics\n",
    "cm_totals = []\n",
    "for cell_type in dataset_cm:\n",
    "    cm_params = []\n",
    "    for param_comb in cell_type:\n",
    "\n",
    "        dataset_stats = {\n",
    "            'Correct division': 0,\n",
    "            'Incorrect division': 0,\n",
    "            'False positive division': 0,\n",
    "            'False negative division': 0\n",
    "        }\n",
    "\n",
    "        for cm in param_comb:\n",
    "            for k in dataset_stats:\n",
    "                dataset_stats[k] += cm[k]\n",
    "\n",
    "        cm_params.append(dataset_stats)\n",
    "    \n",
    "    cm_totals.append(cm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div0.9_b0.99_d0.99\n",
      "3T3\n",
      "{'Correct division': 18, 'False negative division': 6, 'Incorrect division': 0, 'False positive division': 0}\n",
      "HEK293\n",
      "{'Correct division': 32, 'False negative division': 7, 'Incorrect division': 4, 'False positive division': 6}\n",
      "HeLa\n",
      "{'Correct division': 8, 'False negative division': 1, 'Incorrect division': 0, 'False positive division': 0}\n",
      "RAW\n",
      "{'Correct division': 21, 'False negative division': 1, 'Incorrect division': 0, 'False positive division': 4}\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "# Go through each parameter combination\n",
    "for div_param in division:\n",
    "    # For each birth parameter\n",
    "    for birth_param in birth:\n",
    "        # For each death parameter\n",
    "        for death_param in death:\n",
    "\n",
    "            PARAMS = 'div{}_b{}_d{}'.format(div_param, birth_param, death_param)\n",
    "            print(PARAMS)\n",
    "            for i, name in enumerate(['3T3', 'HEK293', 'HeLa', 'RAW']):\n",
    "                print(name)\n",
    "                print(cm_totals[i][counter])\n",
    "\n",
    "            counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ISBI Benchmarking Scripts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ISBI Cell Tracking Challenge Software Required \n",
    "\n",
    "ISBI's Cell Tracking Challenge has a specific [evaluation methodolgy](http://celltrackingchallenge.net/evaluation-methodology/). The evaluation package can be downloaded [here](http://public.celltrackingchallenge.net/software/EvaluationSoftware.zip). Extract the TRAMeasure executable from the zip file and place it in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  3T3\n",
      "Mean:  0.9998178333333333\n",
      "Std. Dev.:  0.0003087691514528082\n",
      "Dataset:  HEK293\n",
      "Mean:  0.9995048076923077\n",
      "Std. Dev.:  0.0006110526238971484\n",
      "Dataset:  HeLa\n",
      "Mean:  0.9942584444444444\n",
      "Std. Dev.:  0.021668905564380152\n",
      "Dataset:  RAW264.7\n",
      "Mean:  0.9996796923076923\n",
      "Std. Dev.:  0.000320740341809237\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import statistics\n",
    "\n",
    "# Confirm the ISBI CTC executable file is available\n",
    "assert os.path.isfile('./TRAMeasure'),'CTC EXE unavailable. See subheading for download instructions.'\n",
    "\n",
    "# Define path to folder containing the directories of interest (ie: 001, 001_GT, 001_RES)\n",
    "bens_folder_names = ['3T3', 'HEK293', 'HeLa', 'RAW264.7']\n",
    "\n",
    "for index, path in enumerate(BENCH_DIRS):\n",
    "    \n",
    "    # Check into parameter folder if neccesary\n",
    "    PARAMS = 'div{}_b{}_d{}'.format(\n",
    "        str(div_param).zfill(3),\n",
    "        str(birth_param).zfill(3),\n",
    "        str(death_param).zfill(3))\n",
    "\n",
    "    path = os.path.abspath(os.path.join(path, PARAMS))\n",
    "\n",
    "    # Calculate the number of batches\n",
    "    dirs = os.listdir(path)\n",
    "    num_batches = int(len(dirs)/3)\n",
    "\n",
    "    TRA_Vals = []\n",
    "    for batch in range(num_batches):\n",
    "        batch = '{:03}'.format(batch+1)\n",
    "\n",
    "        # Run ISBI Tracking Benchmark\n",
    "        p = subprocess.run(['./TRAMeasure', path, batch], stdout=subprocess.PIPE)\n",
    "        # Save the output\n",
    "        outstring = p.stdout\n",
    "\n",
    "        try:\n",
    "            TRA_Val = float(outstring.decode('utf-8').split()[-1])\n",
    "            TRA_Vals.append(TRA_Val)\n",
    "        except:\n",
    "            print('Benchmarking failure - Batch ', batch)\n",
    "            print(outstring.decode('utf-8'))\n",
    "    \n",
    "    print('Dataset: ', bens_folder_names[index])\n",
    "    print('Mean: ', statistics.mean(TRA_Vals))\n",
    "    print('Std. Dev.: ', statistics.pstdev(TRA_Vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
