{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Tracking and Lineage Construction in Live-Cell Imaging Data\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import errno\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (188, 30, 154, 182, 1)\n",
      "y.shape: (188, 30, 154, 182, 1)\n"
     ]
    }
   ],
   "source": [
    "# Download the data (saves to ~/.keras/datasets)\n",
    "filename = '3T3_NIH.trks'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.tracked.nih_3t3.load_tracked_data(filename)\n",
    "\n",
    "print('X.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up filepath constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the data file is currently required for `train_model_()` functions\n",
    "\n",
    "# Change DATA_DIR if you are not using `deepcell.datasets`\n",
    "DATA_DIR = os.path.expanduser(os.path.join('~', '.keras', 'datasets'))\n",
    "DATA_DIR = \"/data/npz_data/cells/HEK293/generic/movie/\"                # USE LOCAL DATA INSTEAD\n",
    "\n",
    "# DATA_FILE should be a trks file (contains 2 np arrays and a lineage dictionary)\n",
    "DATA_FILE = os.path.join(DATA_DIR, filename)\n",
    "DATA_FILE = os.path.join(DATA_DIR, '3T3_HeLa_HEK_corrected.trks')      # USE LOCAL DATA INSTEAD\n",
    "\n",
    "# confirm the data file is available\n",
    "assert os.path.isfile(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up other required filepaths\n",
    "\n",
    "# If the data file is in a subdirectory, mirror it in MODEL_DIR and LOG_DIR\n",
    "PREFIX = os.path.relpath(os.path.dirname(DATA_FILE), DATA_DIR)\n",
    "\n",
    "ROOT_DIR = '/data'  # TODO: Change this! Usually a mounted volume\n",
    "MODEL_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'models', PREFIX))\n",
    "LOG_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'logs', PREFIX))\n",
    "\n",
    "# create directories if they do not exist\n",
    "for d in (MODEL_DIR, LOG_DIR):\n",
    "    try:\n",
    "        os.makedirs(d)\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "tracking_model_name = 'tracking_model'\n",
    "\n",
    "n_epoch = 5  # Number of training epochs\n",
    "test_size = .10  # % of data saved as test\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# Tracking training settings\n",
    "features = {'appearance', 'distance', 'neighborhood', 'regionprop'}\n",
    "min_track_length = 5\n",
    "neighborhood_scale_size=30\n",
    "batch_size = 128  \n",
    "\n",
    "in_shape = (32, 32, 1) # Should this be calculated or hardcoded?\n",
    "seed = 100 # To be removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "#### Instantiate the tracking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "tracking_model = model_zoo.siamese_model(\n",
    "    input_shape=in_shape,\n",
    "    neighborhood_scale_size=neighborhood_scale_size,\n",
    "    features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Train a new tracking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.training import train_model_siamese_daughter\n",
    "\n",
    "tracking_model = train_model_siamese_daughter(\n",
    "    model=tracking_model,\n",
    "    dataset=DATA_FILE,  # full path to trks file\n",
    "    model_name=tracking_model_name,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    min_track_length=min_track_length,\n",
    "    features=features,\n",
    "    neighborhood_scale_size=neighborhood_scale_size,\n",
    "    n_epoch=n_epoch,\n",
    "    model_dir=MODEL_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    class_weight=None,\n",
    "    seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Load an existing tracking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tracking model\n",
    "MODEL_DIR = '/data/models/'\n",
    "PREFIX = 'cells/HEK293/generic/'\n",
    "\n",
    "# Re-instantiate the model and load weights\n",
    "siamese_weights_file = '2019-01-24_3T3_HeLa_HEK_corrected_[a,d,n,r]_neighs=30_epochs=5_seed=360_trks_0.h5'\n",
    "siamese_weights_file = os.path.join(MODEL_DIR, PREFIX, siamese_weights_file)\n",
    "\n",
    "tracking_model.load_weights(siamese_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Model Accuracy with Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DATA_FILE from above to extract Test Data \n",
    "# Change if you are not using `deepcell.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepcell.image_generators as generators\n",
    "from deepcell.utils.data_utils import get_data\n",
    "\n",
    "train_dict, test_dict = get_data(DATA_FILE, mode='siamese_daughters', seed=seed)\n",
    "\n",
    "datagen_test = generators.SiameseDataGenerator(\n",
    "        rotation_range=0,  # randomly rotate images by 0 to rotation_range degrees\n",
    "        shear_range=0,     # randomly shear images in the range (radians , -shear_range to shear_range)\n",
    "        horizontal_flip=0, # randomly flip images\n",
    "        vertical_flip=0)   # randomly flip images\n",
    "\n",
    "test_iterator = generators.SiameseIterator(test_dict,\n",
    "                                           datagen_test,\n",
    "                                           neighborhood_scale_size=neighborhood_scale_size,\n",
    "                                           min_track_length=min_track_length,\n",
    "                                           features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "Y = []\n",
    "Y_pred = []\n",
    "for i in range(1,1001):\n",
    "    if i % 100 == 0:\n",
    "        print(\".\", end=\"\")\n",
    "    lst, y_true = next(test_iterator)\n",
    "    y_true = list(map(np.argmax, y_true))\n",
    "    y_pred = list(map(np.argmax, tracking_model.predict(lst)))\n",
    "    Y.extend(y_true)\n",
    "    Y_pred.extend(y_pred)\n",
    "\n",
    "confusion_matrix(Y, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = sum(np.array(Y) == np.array(Y_pred)) / len(Y)\n",
    "print('Accuracy across all three classes: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Multiple Movies and Generate Track Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DATA_FILE from above for example Test Data \n",
    "# Change if you are not using `deepcell.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize raw images if needed\n",
    "def image_norm(original_image):\n",
    "    # NNs prefer input data that is 0 mean and unit variance\n",
    "    normed_image = (original_image - np.mean(original_image)) / np.std(original_image)\n",
    "    return normed_image\n",
    "\n",
    "for batch in range(test_dict['X'].shape[0]):\n",
    "    for frame in range(test_dict['X'].shape[1]):\n",
    "        test_dict['X'][batch, frame, :, :, 0] = image_norm(test_dict['X'][batch, frame, :, :, 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The tracking model is used in concert with other processes to track cells\n",
    "# Import the neccesary tracking functionality\n",
    "import deepcell.tracking\n",
    "\n",
    "# Define where cell tracks will be saved\n",
    "TRACK_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'track_data', PREFIX))\n",
    "TRACK_FILE_NAME = 'batch_'\n",
    "\n",
    "# create directories if they do not exist\n",
    "try:\n",
    "    os.makedirs(TRACK_DIR)\n",
    "except OSError as exc:  # Guard against race condition\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "\n",
    "# Depending on the number of batches you may not want to track everything at once\n",
    "#num_batches = test_dict['X'].shape[0]\n",
    "num_batches = 2\n",
    "\n",
    "# Generate a cell track for each batch\n",
    "#for batch in range(test_dict['X'].shape[0]):\n",
    "for batch in range(num_batches):\n",
    "    trial = deepcell.tracking.cell_tracker(test_dict['X'][batch], test_dict['y'][batch],\n",
    "                         tracking_model,\n",
    "                         max_distance=200,\n",
    "                         track_length=5, division=0.5, birth=0.9, death=0.9,\n",
    "                         neighborhood_scale_size=30,\n",
    "                         features=features)\n",
    "    trial._track_cells()\n",
    "    file_name = TRACK_FILE_NAME + str(batch).zfill(2) + '.trk'\n",
    "    file_path = os.path.join(TRACK_DIR, file_name)\n",
    "    trial.dump(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bundle individual track files (each batch) into one .trks file for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.utils.tracking_utils import trk_folder_to_trks\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "\n",
    "# Define a name for the trks file\n",
    "SET_NAME = 'all_batches.trks'\n",
    "\n",
    "# Compile trk files into one trks file\n",
    "trk_folder_to_trks(TRACK_DIR,SET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file we created above to review\n",
    "FILE_PATH = os.path.join(os.path.dirname(TRACK_DIR), SET_NAME)\n",
    "trks = load_trks(FILE_PATH)\n",
    "\n",
    "lineages, raw, tracked = trks[\"lineages\"], trks[\"X\"], trks[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw and Tracked Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View tracked results of each batch as a video\n",
    "# NB: This does not render well on GitHub\n",
    "from IPython.display import HTML\n",
    "from deepcell.utils.plot_utils import get_js_video\n",
    "\n",
    "# Change this value to look at other batches of data\n",
    "batch = 0\n",
    "\n",
    "# Raw\n",
    "HTML(get_js_video(raw, batch=batch, cmap='gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracked\n",
    "HTML(get_js_video(tracked, batch=batch, cmap='jet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Raw and Tracked Output as Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define where images (movies) will be saved\n",
    "MOVIE_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'tracked_movies', PREFIX))\n",
    "\n",
    "# create directories if they do not exist\n",
    "try:\n",
    "    os.makedirs(MOVIE_DIR)\n",
    "except OSError as exc:  # Guard against race condition\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "        \n",
    "# Scale the colors to match the max cell label\n",
    "vmax = max(lineages[batch].keys())\n",
    "        \n",
    "channel = 0 # These images should only have one channel\n",
    "for i in range(raw.shape[1]):\n",
    "    name_raw = os.path.join(MOVIE_DIR,'raw_frame_{:02}_.png'.format(i))\n",
    "    name_tracked = os.path.join(MOVIE_DIR,'tracked_frame_{:02}_.png'.format(i))\n",
    "    plt.imsave(name_raw, raw[batch, i, :, :, channel], cmap='gray')\n",
    "    plt.imsave(name_tracked, tracked[batch,i, :, :, channel], cmap='cubehelix', vmin=0, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bechmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Cell Lineages in an ISBI-Formatted Output txt\n",
    "\n",
    "The ISBI Cell Tracking Challenge requires a text file (man_track.txt) that represents a batch's cell lineage as an acyclic graph. The format of this file is as follows: Every line corresponds to a single track that is encoded by four numbers separated by a space -  \n",
    "L B E P  \n",
    "where L is a unique label of the track (label of markers, 16-bit positive value),  \n",
    "B is a zero-based index of the frame in which the track begins,  \n",
    "E is a zero-based index of the frame in which the track ends,  \n",
    "P is the label of the parent track (0 is used when no parent is defined)\n",
    "\n",
    "N.B. DeepCell's unique approach allows for cells to be tracked even if it momentarily leaves the frame. This is not possible in convential tracking algorithms, so ISBI considers a cell's track to have ended once it leaves the frame. We adjust the output here to keep with ISBI's formatting (ie. each track only contains contiguous frames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file we created above and want to translate into ISBI format\n",
    "FILE_PATH = os.path.join(os.path.dirname(TRACK_DIR), SET_NAME)\n",
    "trks = load_trks(FILE_PATH)\n",
    "\n",
    "lineages, raw, tracked = trks[\"lineages\"], trks[\"X\"], trks[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where benchmark data will be saved\n",
    "BENCHMARK_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'tracking_benchmarks', PREFIX))\n",
    "\n",
    "# create directories if they do not exist\n",
    "try:\n",
    "    os.makedirs(BENCHMARK_DIR)\n",
    "except OSError as exc:  # Guard against race condition\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DELETE THIS CELL (TROUBLESHOOTING ONLY):\n",
    "from deepcell.utils.tracking_utils import load_trks\n",
    "from deepcell.utils.tracking_utils import load_trk\n",
    "\n",
    "#FILE_PATH = '/data/track_data/cells/HEK293/all_batches.trks'\n",
    "FILE_PATH = '/data/data/ISBI_Tracking_Challenge/HeLa/nuc/HeLa_Training/01_GT/HEK_model_track/HeLa_01_GT_Batch00.trk'\n",
    "\n",
    "trks = load_trks(FILE_PATH)\n",
    "\n",
    "#lineages, raw, tracked = trks[\"lineages\"], trks[\"X\"], trks[\"y\"]\n",
    "lineages, raw, tracked = trks[\"lineages\"], trks[\"X\"], trks[\"y\"]\n",
    "####### END DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds a new track to the lineage and swap the labels accordingly in the images\n",
    "def create_new_ISBI_track(batch_tracked, batch_info, old_label, frames, daughters, frame_div):\n",
    "    \n",
    "    new_track = len(batch_info.keys())\n",
    "    new_label = new_track + 1\n",
    "         \n",
    "    batch_info[new_label] = {}\n",
    "    batch_info[new_label]['old_label'] = old_label\n",
    "    batch_info[new_label]['label'] = new_label\n",
    "\n",
    "    batch_info[new_label]['frames'] = frames\n",
    "    batch_info[new_label]['daughters'] = daughters\n",
    "    batch_info[new_label]['frame_div'] = frame_div\n",
    "    batch_info[new_label]['parent'] = None\n",
    "\n",
    "    for frame in frames:\n",
    "        batch_tracked[frame][batch_tracked[frame] == old_label] = new_label\n",
    "        \n",
    "    return batch_info, batch_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for contiguous tracks (tracks should only consist of consecutive tracks)\n",
    "# Split one track into two if neccesary\n",
    "def contig_tracks(label, batch_info, batch_tracked):\n",
    "    \n",
    "    original_label = label\n",
    "    frames = batch_info[original_label]['frames']\n",
    "    final_frame_idx = len(frames) - 1\n",
    "   \n",
    "    for frame_idx, frame in enumerate(frames):\n",
    "        next_con_frame = frame + 1\n",
    "        # If the next frame is available and contiguous we should move on to the next frame. Otherwise:\n",
    "        # If the next frame is available and NONcontiguous we should separate this track into two \n",
    "        if frame_idx + 1 <= final_frame_idx and next_con_frame != frames[frame_idx + 1]:\n",
    "            contig_end_idx = frame_idx\n",
    "\n",
    "            next_trk_frames = frames[frame_idx+1:]\n",
    "            daughters = batch_info[original_label]['daughters']\n",
    "            frame_div = batch_info[original_label]['frame_div']\n",
    "            \n",
    "            # Create a new track to hold the information from this frame forward and add it to the batch\n",
    "            batch_info, batch_tracked = create_new_ISBI_track(batch_tracked, batch_info, original_label, \n",
    "                                                                next_trk_frames, daughters, frame_div)\n",
    "            \n",
    "            # Adjust the info for the current track to vacate the new track info\n",
    "            batch_info[original_label]['frames'] = frames[0:contig_end_idx]\n",
    "            batch_info[original_label]['daughters'] = []\n",
    "            batch_info[original_label]['frame_div'] = None\n",
    "            \n",
    "            # Because we are splitting tracks recursively, we stop here\n",
    "            break\n",
    "        \n",
    "        # If the current frame is the last frame then were done\n",
    "        # Either the last frame is contiguous and we don't alter batch_info\n",
    "        # or it's not and it's been made into a new track by the previous iteration of the loop\n",
    "        \n",
    "    return batch_info, batch_tracked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:  0\n",
      "1 0 20 0\n",
      "2 0 29 0\n",
      "3 0 29 0\n",
      "4 0 29 0\n",
      "5 0 29 0\n",
      "6 0 29 0\n",
      "7 0 29 0\n",
      "8 0 29 0\n",
      "9 0 6 0\n",
      "10 0 29 0\n",
      "11 7 29 0\n",
      "12 7 15 0\n",
      "13 7 29 0\n",
      "14 21 29 1\n",
      "15 21 21 1\n",
      "16 20 24 0\n",
      "17 27 28 0\n",
      "batch number:  1\n",
      "1 0 29 0\n",
      "2 0 29 0\n",
      "3 0 29 0\n",
      "4 0 29 0\n",
      "5 0 29 0\n",
      "6 0 29 0\n",
      "7 0 29 0\n",
      "8 0 29 0\n",
      "9 0 1 0\n",
      "10 6 29 0\n"
     ]
    }
   ],
   "source": [
    "# Translate track data to ISBI format and provide outputs for benchmarking\n",
    "# Record lineage data in txt as it is generated\n",
    "\n",
    "for batch, batch_info in enumerate(lineages):\n",
    "    print('batch number: ', batch)\n",
    "    \n",
    "    # Build subdirectories to hold benchmark info\n",
    "    B_SUB_DIR = os.path.join(BENCHMARK_DIR, '{:02}_RES'.format(batch+1))\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    try:\n",
    "        os.makedirs(B_SUB_DIR)\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "    \n",
    "    # Prepare output txt\n",
    "    text_file = open(os.path.join(B_SUB_DIR, \"res_track.txt\"), \"w\")\n",
    "    \n",
    "    batch_tracked = tracked[batch]\n",
    "    labels = list(batch_info.keys())\n",
    "    max_label = max(labels)\n",
    "    \n",
    "    for label in labels:\n",
    "        batch_info, batch_tracked = contig_tracks(label, batch_info, batch_tracked)\n",
    "                \n",
    "        first_frame = np.amin(batch_info[label]['frames'])\n",
    "        last_frame = np.amax(batch_info[label]['frames'])\n",
    "        if batch_info[label]['parent']:\n",
    "            parent = batch_info[label]['parent']\n",
    "        else:\n",
    "            parent = 0\n",
    "\n",
    "        print(label, first_frame, last_frame, parent)\n",
    "        text_file.write('{} {} {} {}\\n'.format(label, first_frame, last_frame, parent))\n",
    "        \n",
    "        # Check if the track need to be split\n",
    "        if max(batch_info.keys()) > max_label:\n",
    "            # If so, a new track was added\n",
    "            new_max_label = max(batch_info.keys())\n",
    "            labels.append(new_max_label)\n",
    "            max_label = new_max_label\n",
    "        \n",
    "    text_file.close()\n",
    "    lineages[batch] = batch_info\n",
    "    tracked[batch] = batch_tracked\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate new images to match the new ISBI-formatted lineage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch number:  0\n",
      "batch number:  1\n"
     ]
    }
   ],
   "source": [
    "from skimage.external.tifffile import imsave\n",
    "\n",
    "for batch, batch_info in enumerate(lineages):\n",
    "    print('batch number: ', batch)\n",
    "    \n",
    "    # check into appropriate benchmark subdirectory\n",
    "    B_SUB_DIR = os.path.join(BENCHMARK_DIR, '{:02}_RES'.format(batch+1))\n",
    "    \n",
    "    # Scale the colors of the labeled images to match the max cell label\n",
    "    vmax = max(lineages[batch].keys())\n",
    "\n",
    "    channel = 0 # These images should only have one channel\n",
    "    for i in range(raw.shape[1]):\n",
    "#        name_raw = os.path.join(B_SUB_DIR,'raw_frame_{:03}_.tif'.format(i))\n",
    "        name_tracked = os.path.join(B_SUB_DIR,'mask{:03}.tif'.format(i))\n",
    "#        imsave(name_raw, raw[batch, i, :, :, channel], cmap='gray')\n",
    "        imsave(name_tracked, tracked[batch,i, :, :, channel])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
