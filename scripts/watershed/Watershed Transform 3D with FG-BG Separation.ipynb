{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watershed distance transform for 3-dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import errno\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.optimizers import SGD, Adam\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "import deepcell as dc\n",
    "from deepcell import get_data\n",
    "from deepcell import make_training_data\n",
    "from deepcell import rate_scheduler\n",
    "from deepcell.model_zoo import bn_feature_net_3D\n",
    "from deepcell.model_zoo import bn_feature_net_11x61x61_3D\n",
    "from deepcell.model_zoo import dilated_bn_feature_net_11x61x61_3D\n",
    "from deepcell.training import train_model_movie\n",
    "from deepcell.training import train_model_sample_movie\n",
    "from deepcell.training import train_model_watershed_3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Based Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUTPUT_MODE = 'conv'\n",
    "BORDER_MODE = 'same'\n",
    "RESIZE = False\n",
    "RESHAPE_SIZE = 256\n",
    "NUM_FRAMES = 30  # get first N frames from each training folder\n",
    "BINS = 4  # number of distance bins to classify\n",
    "\n",
    "# filepath constants\n",
    "DATA_DIR = '/data/data'\n",
    "MODEL_DIR = '/data/models'\n",
    "NPZ_DIR = '/data/npz_data'\n",
    "RESULTS_DIR = '/data/results'\n",
    "EXPORT_DIR = '/data/exports'\n",
    "PREFIX = 'cells/MouseBrain/generic'\n",
    "CONV_DATA_FILE = 'MouseBrain_3d_watershed_{}'.format(DATA_OUTPUT_MODE)\n",
    "\n",
    "# Check for channels_first or channels_last\n",
    "IS_CHANNELS_FIRST = K.image_data_format() == 'channels_first'\n",
    "\n",
    "ROW_AXIS = 3 if IS_CHANNELS_FIRST else 2\n",
    "COL_AXIS = 4 if IS_CHANNELS_FIRST else 3\n",
    "CHANNEL_AXIS = 1 if IS_CHANNELS_FIRST else 4\n",
    "\n",
    "# create these directories if they do not exist\n",
    "for d in (NPZ_DIR, MODEL_DIR, RESULTS_DIR):\n",
    "    try:\n",
    "        os.makedirs(os.path.join(d, PREFIX))\n",
    "        print('Created new directory:', os.path.join(d, PREFIX))\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training data\n",
    "make_training_data(\n",
    "    dimensionality=3,\n",
    "    direc_name=os.path.join(DATA_DIR, PREFIX),\n",
    "    file_name_save=os.path.join(NPZ_DIR, PREFIX, CONV_DATA_FILE),\n",
    "    channel_names=['slice'],  # for iterating over stacks of images from a montage\n",
    "    training_direcs=['set6'],\n",
    "    output_mode=DATA_OUTPUT_MODE,\n",
    "    window_size_x=30,\n",
    "    window_size_y=30,\n",
    "    window_size_z=3,\n",
    "    border_mode=BORDER_MODE,\n",
    "    reshape_size=None if not RESIZE else RESHAPE_SIZE,\n",
    "    process=True,\n",
    "    process_std=True,\n",
    "    display=False,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    num_of_frames_to_display=5,\n",
    "    verbose=True,\n",
    "    montage_mode=True,  # annotation folder has montaged sub-dirs\n",
    "    annotation_name='',  # basically channel name but for annotated images\n",
    "    raw_image_direc='stacked_raw',\n",
    "    annotation_direc='annotated/all_montages')\n",
    "\n",
    "if os.path.isfile(os.path.join(NPZ_DIR, PREFIX, CONV_DATA_FILE) + '.npz'):\n",
    "    print('\\nData saved to', os.path.join(NPZ_DIR, PREFIX, CONV_DATA_FILE) + '.npz')\n",
    "else:\n",
    "    raise Exception('Uh Oh!  Your data file did not save properly :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from NPZ into a numpy array\n",
    "training_data = np.load(os.path.join(NPZ_DIR, PREFIX, CONV_DATA_FILE + '.npz'))\n",
    "\n",
    "X, y = training_data['X'], training_data['y']\n",
    "print('X.shape: {}\\ny.shape: {}'.format(X.shape, y.shape))\n",
    "\n",
    "# Set up training parameters\n",
    "n_epoch = 16\n",
    "batch_size = 1\n",
    "frames_per_batch = 10\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# save the size of the input data for batch_shape model parameter\n",
    "size = (RESHAPE_SIZE, RESHAPE_SIZE) if RESIZE else X.shape[ROW_AXIS:COL_AXIS + 1]\n",
    "if IS_CHANNELS_FIRST:\n",
    "    batch_shape = (batch_size, X.shape[CHANNEL_AXIS], frames_per_batch, size[0], size[1])\n",
    "else:\n",
    "    batch_shape = (batch_size, frames_per_batch, size[0], size[1], X.shape[CHANNEL_AXIS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a foreground/background separation model\n",
    "\n",
    "# Instantiate the model\n",
    "fgbg_model = bn_feature_net_3D(\n",
    "    n_features=2,  # segmentation mask (is_cell, is_not_cell)\n",
    "    batch_shape=batch_shape,\n",
    "    norm_method='whole_image')\n",
    "\n",
    "# Train the model\n",
    "train_model_movie(\n",
    "    model=fgbg_model,\n",
    "    expt='fgbg',\n",
    "    dataset=CONV_DATA_FILE,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    number_of_frames=frames_per_batch,\n",
    "    n_epoch=n_epoch,\n",
    "    direc_save=os.path.join(MODEL_DIR, PREFIX),\n",
    "    direc_data=os.path.join(NPZ_DIR, PREFIX),\n",
    "    lr_sched=rate_scheduler(lr=0.01, decay=0.95),\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Next, Create a model for the watershed energy transform\n",
    "\n",
    "# Instantiate the model\n",
    "watershed_model = bn_feature_net_3D(\n",
    "    n_features=BINS,\n",
    "    batch_shape=batch_shape,\n",
    "    norm_method='whole_image')\n",
    "\n",
    "# Train the model\n",
    "train_model_watershed_3D(\n",
    "    model=watershed_model,\n",
    "    expt='watershed',\n",
    "    dataset=CONV_DATA_FILE,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    n_epoch=n_epoch,\n",
    "    distance_bins=BINS,\n",
    "    direc_save=os.path.join(MODEL_DIR, PREFIX),\n",
    "    direc_data=os.path.join(NPZ_DIR, PREFIX),\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the trained model, make predictions on testing data\n",
    "training_data_file = os.path.join(NPZ_DIR, PREFIX, CONV_DATA_FILE + '.npz')\n",
    "\n",
    "train_dict, (X_test, y_test) = get_data(\n",
    "    training_data_file, mode=DATA_OUTPUT_MODE, seed=21)\n",
    "\n",
    "# To predict on variable number of frames\n",
    "# we need to re-instantiate model and load weights\n",
    "model_fn = bn_feature_net_3D\n",
    "watershed_weights_file = '2018-07-15_MouseBrain_3d_watershed_conv_watershed_0.h5'\n",
    "watershed_weights_file = os.path.join(MODEL_DIR, PREFIX, watershed_weights_file)\n",
    "\n",
    "fg_bg_weights_file = '2018-07-15_MouseBrain_3d_watershed_conv_fgbg_0.h5'\n",
    "fg_bg_weights_file = os.path.join(MODEL_DIR, PREFIX, fg_bg_weights_file)\n",
    "\n",
    "fgbg_model = model_fn(n_features=2, batch_shape=X_test.shape, norm_method='whole_image')\n",
    "fgbg_model.load_weights(fg_bg_weights_file)\n",
    "\n",
    "watershed_model = model_fn(n_features=BINS, batch_shape=X_test.shape, norm_method='whole_image')\n",
    "watershed_model.load_weights(watershed_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = watershed_model.predict(X_test)\n",
    "test_images_fgbg = fgbg_model.predict(X_test)\n",
    "\n",
    "print('watershed transform shape:', test_images.shape)\n",
    "print('segmentation mask shape:', test_images_fgbg.shape)\n",
    "\n",
    "argmax_images = []\n",
    "for i in range(test_images.shape[0]):\n",
    "    max_image = np.argmax(test_images[i], axis=CHANNEL_AXIS - 1)\n",
    "    argmax_images.append(max_image)\n",
    "argmax_images = np.array(argmax_images)\n",
    "argmax_images = np.expand_dims(argmax_images, axis=CHANNEL_AXIS)\n",
    "\n",
    "print('watershed argmax shape:', argmax_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold the foreground/background\n",
    "# and remove back ground from watershed transform\n",
    "threshold = 0.8\n",
    "if IS_CHANNELS_FIRST:\n",
    "    fg_thresh = test_images_fgbg[:, 1, :, :, :] > threshold\n",
    "else:\n",
    "    fg_thresh = test_images_fgbg[:, :, :, :, 1] > threshold\n",
    "\n",
    "fg_thresh = np.expand_dims(fg_thresh.astype(np.int16), axis=CHANNEL_AXIS)\n",
    "argmax_images_post_fgbg = argmax_images * fg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply watershed method with the distance transform as seed\n",
    "from scipy import ndimage\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "watershed_images = []\n",
    "for i in range(argmax_images_post_fgbg.shape[0]):\n",
    "    if IS_CHANNELS_FIRST:\n",
    "        image = fg_thresh[i, 0, :, :, :]\n",
    "        distance = argmax_images_post_fgbg[i, 0, :, :, :]\n",
    "    else:\n",
    "        image = fg_thresh[i, :, :, :, 0]\n",
    "        distance = argmax_images_post_fgbg[i, :, :, :, 0]\n",
    "\n",
    "    local_maxi = peak_local_max(distance, min_distance=10, indices=False, labels=image)\n",
    "\n",
    "    markers = ndimage.label(local_maxi)[0]\n",
    "    segments = watershed(-distance, markers, mask=image)\n",
    "    watershed_images.append(segments)\n",
    "\n",
    "watershed_images = np.array(watershed_images)\n",
    "watershed_images = np.expand_dims(watershed_images, axis=CHANNEL_AXIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "index = 0\n",
    "frame = 19\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(15, 15), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(X_test[index, frame, :, :, 0])\n",
    "ax[0].set_title('Source Image')\n",
    "\n",
    "ax[1].imshow(test_images_fgbg[index, frame, :, :, 1])\n",
    "ax[1].set_title('Segmentation Prediction')\n",
    "\n",
    "ax[2].imshow(fg_thresh[index, frame, :, :, 0], cmap='jet')\n",
    "ax[2].set_title('Thresholded Segmentation')\n",
    "\n",
    "ax[3].imshow(argmax_images[index, frame, :, :, 0], cmap='jet')\n",
    "ax[3].set_title('Watershed Transform')\n",
    "\n",
    "ax[4].imshow(argmax_images_post_fgbg[index, frame, :, :, 0], cmap='jet')\n",
    "ax[4].set_title('Watershed Transform w/o Background')\n",
    "\n",
    "ax[5].imshow(watershed_images[index, frame, :, :, 0], cmap='jet')\n",
    "ax[5].set_title('Watershed Segmentation')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Based Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUTPUT_MODE = 'sample'\n",
    "BORDER_MODE = 'valid'\n",
    "RESIZE = False\n",
    "RESHAPE_SIZE = 256\n",
    "NUM_FRAMES = 30\n",
    "BINS = 4\n",
    "\n",
    "# filepath constants\n",
    "DATA_DIR = '/data/data'\n",
    "MODEL_DIR = '/data/models'\n",
    "NPZ_DIR = '/data/npz_data'\n",
    "RESULTS_DIR = '/data/results'\n",
    "EXPORT_DIR = '/data/exports'\n",
    "PREFIX = 'cells/MouseBrain/generic'\n",
    "WATERSHED_DATA_FILE = 'MouseBrain_3d_watershed_{}'.format(DATA_OUTPUT_MODE)\n",
    "FG_BG_DATA_FILE = 'MouseBrain_3d_{}'.format(DATA_OUTPUT_MODE)\n",
    "\n",
    "# Check for channels_first or channels_last\n",
    "IS_CHANNELS_FIRST = K.image_data_format() == 'channels_first'\n",
    "\n",
    "ROW_AXIS = 3 if IS_CHANNELS_FIRST else 2\n",
    "COL_AXIS = 4 if IS_CHANNELS_FIRST else 3\n",
    "CHANNEL_AXIS = 1 if IS_CHANNELS_FIRST else 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make the training data for foreground/background segmentation\n",
    "make_training_data(\n",
    "    dimensionality=3,\n",
    "    direc_name=os.path.join(DATA_DIR, PREFIX),\n",
    "    file_name_save=os.path.join(NPZ_DIR, PREFIX, FG_BG_DATA_FILE),\n",
    "    channel_names=['slice'],  # for iterating over stacks of images from a montage\n",
    "    training_direcs=['set6'],\n",
    "    output_mode=DATA_OUTPUT_MODE,\n",
    "    max_training_examples=1e5,\n",
    "    window_size_x=30,\n",
    "    window_size_y=30,\n",
    "    window_size_z=3,\n",
    "    border_mode=BORDER_MODE,\n",
    "    reshape_size=None if not RESIZE else RESHAPE_SIZE,\n",
    "    distance_transform=False,\n",
    "    distance_bins=4,\n",
    "    display=False,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    num_of_frames_to_display=5,\n",
    "    verbose=False,\n",
    "    montage_mode=True,  # annotation folder has montaged sub-dirs\n",
    "    annotation_name='',  # basically channel name but for annotated images\n",
    "    raw_image_direc='stacked_raw',\n",
    "    annotation_direc='annotated/all_montages')\n",
    "\n",
    "if os.path.isfile(os.path.join(NPZ_DIR, PREFIX, FG_BG_DATA_FILE) + '.npz'):\n",
    "    print('Data Saved to', os.path.join(NPZ_DIR, PREFIX, FG_BG_DATA_FILE) + '.npz')\n",
    "else:\n",
    "    raise Exception('Uh Oh!  Your data file did not save properly :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make the training data for foreground/background segmentation\n",
    "make_training_data(\n",
    "    dimensionality=3,\n",
    "    direc_name=os.path.join(DATA_DIR, PREFIX),\n",
    "    file_name_save=os.path.join(NPZ_DIR, PREFIX, WATERSHED_DATA_FILE),\n",
    "    channel_names=['slice'],  # for iterating over stacks of images from a montage\n",
    "    training_direcs=['set6'],\n",
    "    output_mode=DATA_OUTPUT_MODE,\n",
    "    max_training_examples=1e5,\n",
    "    window_size_x=30,\n",
    "    window_size_y=30,\n",
    "    window_size_z=3,\n",
    "    border_mode=BORDER_MODE,\n",
    "    reshape_size=None if not RESIZE else RESHAPE_SIZE,\n",
    "    distance_transform=True,\n",
    "    distance_bins=4,\n",
    "    display=False,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    num_of_frames_to_display=5,\n",
    "    verbose=False,\n",
    "    montage_mode=True,  # annotation folder has montaged sub-dirs\n",
    "    annotation_name='',  # basically channel name but for annotated images\n",
    "    raw_image_direc='stacked_raw',\n",
    "    annotation_direc='annotated/all_montages')\n",
    "\n",
    "if os.path.isfile(os.path.join(NPZ_DIR, PREFIX, WATERSHED_DATA_FILE) + '.npz'):\n",
    "    print('Data Saved to', os.path.join(NPZ_DIR, PREFIX, WATERSHED_DATA_FILE) + '.npz')\n",
    "else:\n",
    "    raise Exception('Uh Oh!  Your data file did not save properly :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from NPZ into a numpy array\n",
    "training_data = np.load(os.path.join(NPZ_DIR, PREFIX, FG_BG_DATA_FILE + '.npz'))\n",
    "\n",
    "X, y = training_data['X'], training_data['y']\n",
    "print('X.shape: {}\\ny.shape: {}'.format(X.shape, y.shape))\n",
    "\n",
    "# Set up training parameters\n",
    "n_epoch = 16\n",
    "batch_size = 32\n",
    "frames_per_batch = 10\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a foreground/background separation model\n",
    "\n",
    "# Instantiate the model\n",
    "fgbg_model = bn_feature_net_11x61x61_3D(\n",
    "    n_features=2,\n",
    "    n_channels=X.shape[CHANNEL_AXIS])\n",
    "\n",
    "# Train the model\n",
    "train_model_sample_movie(\n",
    "    model=fgbg_model,\n",
    "    dataset=FG_BG_DATA_FILE,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    n_epoch=n_epoch,\n",
    "    direc_save=os.path.join(MODEL_DIR, PREFIX),\n",
    "    direc_data=os.path.join(NPZ_DIR, PREFIX),\n",
    "    expt='fgbg',\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from NPZ into a numpy array\n",
    "training_data = np.load(os.path.join(NPZ_DIR, PREFIX, WATERSHED_DATA_FILE + '.npz'))\n",
    "\n",
    "X, y = training_data['X'], training_data['y']\n",
    "print('X.shape: {}\\ny.shape: {}'.format(X.shape, y.shape))\n",
    "\n",
    "# Set up training parameters\n",
    "n_epoch = 16\n",
    "batch_size = 32\n",
    "frames_per_batch = 10\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, Create a model for the watershed energy transform\n",
    "\n",
    "# Instantiate the model\n",
    "watershed_model = bn_feature_net_11x61x61_3D(\n",
    "    n_features=BINS,\n",
    "    n_channels=X.shape[CHANNEL_AXIS])\n",
    "\n",
    "# Train the model\n",
    "train_model_sample_movie(\n",
    "    model=watershed_model,\n",
    "    dataset=WATERSHED_DATA_FILE,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    n_epoch=n_epoch,\n",
    "    direc_save=os.path.join(MODEL_DIR, PREFIX),\n",
    "    direc_data=os.path.join(NPZ_DIR, PREFIX),\n",
    "    expt='watershed',\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the trained models, make predictions on testing data\n",
    "training_data_file = os.path.join(NPZ_DIR, PREFIX, CONV_DATA_FILE + '.npz')\n",
    "\n",
    "train_dict, (X_test, y_test) = get_data(\n",
    "    training_data_file, mode='conv', seed=21)\n",
    "\n",
    "# Re-initializing dilated models for sample-mode predictions\n",
    "model_fn = dilated_bn_feature_net_11x61x61_3D\n",
    "\n",
    "watershed_weights_file = '2018-07-16_MouseBrain_3d_watershed_sample_watershed_0.h5'\n",
    "watershed_weights_file = os.path.join(MODEL_DIR, PREFIX, watershed_weights_file)\n",
    "\n",
    "fg_bg_weights_file = '2018-07-15_MouseBrain_3d_sample_fgbg_0.h5'\n",
    "fg_bg_weights_file = os.path.join(MODEL_DIR, PREFIX, fg_bg_weights_file)\n",
    "\n",
    "run_watershed_model = dilated_bn_feature_net_11x61x61_3D(\n",
    "    n_features=BINS,\n",
    "    input_shape=X_test.shape[1:])\n",
    "run_watershed_model.load_weights(watershed_weights_file, by_name=True)\n",
    "\n",
    "run_fgbg_model = dilated_bn_feature_net_11x61x61_3D(\n",
    "    n_features=2,\n",
    "    input_shape=X_test.shape[1:])\n",
    "run_fgbg_model.load_weights(fg_bg_weights_file, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the trained models, make predictions on testing data\n",
    "test_images = run_watershed_model.predict(X_test)\n",
    "test_images_fgbg = run_fgbg_model.predict(X_test)\n",
    "\n",
    "print('watershed transform shape:', test_images.shape)\n",
    "print('segmentation mask shape:', test_images_fgbg.shape)\n",
    "\n",
    "argmax_images = []\n",
    "for i in range(test_images.shape[0]):\n",
    "    max_image = np.argmax(test_images[i], axis=CHANNEL_AXIS - 1)\n",
    "    argmax_images.append(max_image)\n",
    "argmax_images = np.array(argmax_images)\n",
    "argmax_images = np.expand_dims(argmax_images, axis=CHANNEL_AXIS)\n",
    "\n",
    "print('watershed argmax shape:', argmax_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold the foreground/background\n",
    "# and remove back ground from watershed transform\n",
    "threshold = 0.8\n",
    "if IS_CHANNELS_FIRST:\n",
    "    fg_thresh = test_images_fgbg[:, 1, :, :, :] > threshold\n",
    "else:\n",
    "    fg_thresh = test_images_fgbg[:, :, :, :, 1] > threshold\n",
    "\n",
    "fg_thresh = np.expand_dims(fg_thresh.astype(np.int16), axis=CHANNEL_AXIS)\n",
    "argmax_images_post_fgbg = argmax_images * fg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply watershed method with the distance transform as seed\n",
    "from scipy import ndimage\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "watershed_images = []\n",
    "for i in range(argmax_images_post_fgbg.shape[0]):\n",
    "    if IS_CHANNELS_FIRST:\n",
    "        image = fg_thresh[i, 0, :, :, :]\n",
    "        distance = argmax_images_post_fgbg[i, 0, :, :, :]\n",
    "    else:\n",
    "        image = fg_thresh[i, :, :, :, 0]\n",
    "        distance = argmax_images_post_fgbg[i, :, :, :, 0]\n",
    "\n",
    "    local_maxi = peak_local_max(distance, min_distance=10, indices=False, labels=image)\n",
    "\n",
    "    markers = ndimage.label(local_maxi)[0]\n",
    "    segments = watershed(-distance, markers, mask=image)\n",
    "    watershed_images.append(segments)\n",
    "\n",
    "watershed_images = np.array(watershed_images)\n",
    "watershed_images = np.expand_dims(watershed_images, axis=CHANNEL_AXIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "index = 1\n",
    "frame = 14\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(15, 15), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(X_test[index, frame, :, :, 0])\n",
    "ax[0].set_title('Source Image')\n",
    "\n",
    "ax[1].imshow(test_images_fgbg[index, frame, :, :, 1])\n",
    "ax[1].set_title('Segmentation Prediction')\n",
    "\n",
    "ax[2].imshow(fg_thresh[index, frame, :, :, 0], cmap='jet')\n",
    "ax[2].set_title('Thresholded Segmentation')\n",
    "\n",
    "ax[3].imshow(argmax_images[index, frame, :, :, 0], cmap='jet')\n",
    "ax[3].set_title('Watershed Transform')\n",
    "\n",
    "ax[4].imshow(argmax_images_post_fgbg[index, frame, :, :, 0], cmap='jet')\n",
    "ax[4].set_title('Watershed Transform w/o Background')\n",
    "\n",
    "ax[5].imshow(watershed_images[index, frame, :, :, 0], cmap='jet')\n",
    "ax[5].set_title('Watershed Segmentation')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
