{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import errno\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import deepcell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://deepcell-data.s3.amazonaws.com/nuclei/mousebrain.npz\n",
      "1730158592/1730150850 [==============================] - 68s 0us/step\n",
      "X.shape: (176, 15, 256, 256, 1)\n",
      "y.shape: (176, 15, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Download the data (saves to ~/.keras/datasets)\n",
    "filename = 'mousebrain.npz'\n",
    "(X_train, y_train), (X_test, y_test) = deepcell.datasets.mousebrain.load_data(filename)\n",
    "\n",
    "print('X.shape: {}\\ny.shape: {}'.format(X_train.shape, y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up filepath constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the path to the data file is currently required for `train_model_()` functions\n",
    "\n",
    "# change DATA_DIR if you are not using `deepcell.datasets`\n",
    "DATA_DIR = os.path.expanduser(os.path.join('~', '.keras', 'datasets'))\n",
    "\n",
    "# DATA_FILE should be a npz file, preferably from `make_training_data`\n",
    "DATA_FILE = os.path.join(DATA_DIR, filename)\n",
    "\n",
    "# confirm the data file is available\n",
    "assert os.path.isfile(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up other required filepaths\n",
    "\n",
    "# If the data file is in a subdirectory, mirror it in MODEL_DIR and LOG_DIR\n",
    "PREFIX = os.path.relpath(os.path.dirname(DATA_FILE), DATA_DIR)\n",
    "\n",
    "ROOT_DIR = '/data'  # TODO: Change this! Usually a mounted volume\n",
    "MODEL_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'models', PREFIX))\n",
    "LOG_DIR = os.path.abspath(os.path.join(ROOT_DIR, 'logs', PREFIX))\n",
    "\n",
    "# create directories if they do not exist\n",
    "for d in (MODEL_DIR, LOG_DIR):\n",
    "    try:\n",
    "        os.makedirs(d)\n",
    "    except OSError as exc:  # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from deepcell.utils.train_utils import rate_scheduler\n",
    "\n",
    "n_epoch = 1  # Number of training epochs\n",
    "test_size = .10  # % of data saved as test\n",
    "receptive_field = 61  # should be adjusted for the scale of the data\n",
    "\n",
    "optimizer = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "lr_sched = rate_scheduler(lr=0.01, decay=0.99)\n",
    "\n",
    "# Transformation settings\n",
    "transform = 'deepcell'\n",
    "dilation_radius = 1  # change dilation radius for edge dilation\n",
    "n_features = 4  # (cell-background edge, cell-cell edge, cell interior, background)\n",
    "\n",
    "# 3D Settings\n",
    "frames_per_batch = 3\n",
    "norm_method = 'whole_image'  # data normalization - `whole_image` for 3d conv\n",
    "\n",
    "# Sample mode settings\n",
    "batch_size = 64  # number of images per batch (should be 2 ^ n)\n",
    "win = (receptive_field - 1) // 2  # sample window size\n",
    "win_z = (frames_per_batch - 1) // 2 # z window size\n",
    "balance_classes = True  # sample each class equally\n",
    "max_class_samples = 1e6  # max number of samples per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, create a foreground/background separation model\n",
    "\n",
    "#### Instantiate the fgbg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "fgbg_model = model_zoo.bn_feature_net_3D(\n",
    "    receptive_field=receptive_field,\n",
    "    n_features=2,\n",
    "    norm_method=norm_method,\n",
    "    n_frames=frames_per_batch,\n",
    "    n_channels=X_train.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (198, 15, 256, 256, 1)\n",
      "y_train shape: (198, 15, 256, 256, 1)\n",
      "X_test shape: (22, 15, 256, 256, 1)\n",
      "y_test shape: (22, 15, 256, 256, 1)\n",
      "Output Shape: (None, 2)\n",
      "Number of Classes: 2\n",
      "Training on 1 GPUs\n",
      "Epoch 1/1\n",
      "31084/31085 [============================>.] - ETA: 0s - loss: 0.1899 - acc: 0.9310\n",
      "Epoch 00001: val_loss improved from inf to 0.16294, saving model to /data/models/2018-12-18_mousebrain_sample_fgbg.h5\n",
      "31085/31085 [==============================] - 2921s 94ms/step - loss: 0.1899 - acc: 0.9310 - val_loss: 0.1629 - val_acc: 0.9398\n"
     ]
    }
   ],
   "source": [
    "from deepcell.training import train_model_sample\n",
    "\n",
    "fgbg_model = train_model_sample(\n",
    "    model=fgbg_model,\n",
    "    dataset=DATA_FILE,  # full path to npz file\n",
    "    window_size=(win, win, (frames_per_batch - 1) // 2),\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    balance_classes=balance_classes,\n",
    "    max_class_samples=max_class_samples,\n",
    "    transform='fgbg',\n",
    "    n_epoch=n_epoch,\n",
    "    model_dir=MODEL_DIR,\n",
    "    expt='sample_fgbg',\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, Create a model for the edge/interior transform\n",
    "\n",
    "#### Instantiate the deepcell transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell import model_zoo\n",
    "\n",
    "sample_model = model_zoo.bn_feature_net_61x61_3D(\n",
    "    n_features=4,  # (background edge, interior edge, cell interior, background)\n",
    "    n_frames=frames_per_batch,\n",
    "    norm_method=norm_method,\n",
    "    n_channels=X_train.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the deepcell transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (198, 15, 256, 256, 1)\n",
      "y_train shape: (198, 15, 256, 256, 1)\n",
      "X_test shape: (22, 15, 256, 256, 1)\n",
      "y_test shape: (22, 15, 256, 256, 1)\n",
      "Output Shape: (None, 4)\n",
      "Number of Classes: 4\n",
      "Training on 1 GPUs\n"
     ]
    }
   ],
   "source": [
    "from deepcell.training import train_model_sample\n",
    "\n",
    "sample_model = train_model_sample(\n",
    "    model=sample_model,\n",
    "    dataset=DATA_FILE,  # full path to npz file\n",
    "    window_size=(win, win, (frames_per_batch - 1) // 2),\n",
    "    expt='conv',\n",
    "    test_size=test_size,\n",
    "    transform=transform,\n",
    "    dilation_radius=dilation_radius,\n",
    "    optimizer=optimizer,\n",
    "    batch_size=batch_size,\n",
    "    balance_classes=balance_classes,\n",
    "    max_class_samples=max_class_samples,\n",
    "    n_epoch=n_epoch,\n",
    "    log_dir=LOG_DIR,\n",
    "    model_dir=MODEL_DIR,\n",
    "    lr_sched=lr_sched,\n",
    "    rotation_range=180,\n",
    "    flip=True,\n",
    "    shear=False,\n",
    "    zoom_range=(0.8, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model\n",
    "\n",
    "The model was trained on small samples of data of shape `(receptive_field, receptive_field)`.\n",
    "in order to process full-sized images, the trained weights will be saved and loaded into a new model with `dilated=True` and proper `input_shape`.\n",
    "\n",
    "#### Save weights of trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgbg_weights_file = os.path.join(MODEL_DIR, '{}_{}_fgbg_sample.h5'.format(\n",
    "    datetime.datetime.now().strftime('%Y-%m-%d'),\n",
    "    os.path.splitext(os.path.basename(DATA_FILE))[0]\n",
    "))\n",
    "fgbg_model.save_weights(fgbg_weights_file)\n",
    "\n",
    "sample_weights_file = os.path.join(MODEL_DIR, '{}_{}_{}.h5'.format(\n",
    "    datetime.datetime.now().strftime('%Y-%m-%d'),\n",
    "    os.path.splitext(os.path.basename(DATA_FILE))[0],\n",
    "    '{}_sample'.format(transform)\n",
    "))\n",
    "sample_model.save_weights(sample_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize dilated models and load the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fgbg_model = bn_feature_net_3D(\n",
    "    receptive_field=receptive_field,\n",
    "    dilated=True,\n",
    "    n_features=2,\n",
    "    n_frames=frames_per_batch,\n",
    "    input_shape=tuple(X_test.shape[1:]))\n",
    "run_fgbg_model.load_weights(fgbg_weights_file)\n",
    "\n",
    "run_watershed_model = bn_feature_net_3D(\n",
    "    receptive_field=receptive_field,\n",
    "    dilated=True,\n",
    "    n_features=distance_bins,\n",
    "    n_frames=frames_per_batch,\n",
    "    input_shape=tuple(X_test.shape[1:]))\n",
    "run_watershed_model.load_weights(watershed_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = run_watershed_model.predict(X_test[:4])\n",
    "test_images_fgbg = run_fgbg_model.predict(X_test[:4])\n",
    "\n",
    "print('edge/interior shape:', test_images.shape)\n",
    "print('fgbg mask shape:', test_images_fgbg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_images = []\n",
    "for i in range(test_images.shape[0]):\n",
    "    max_image = np.argmax(test_images[i], axis=-2)\n",
    "    argmax_images.append(max_image)\n",
    "argmax_images = np.array(argmax_images)\n",
    "argmax_images = np.expand_dims(argmax_images, axis=-1)\n",
    "\n",
    "print('watershed argmax shape:', argmax_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold the foreground/background\n",
    "# and remove back ground from watershed transform\n",
    "threshold = 0.8\n",
    "fg_thresh = test_images_fgbg[..., 1] > threshold\n",
    "\n",
    "fg_thresh = np.expand_dims(fg_thresh, axis=-1)\n",
    "argmax_images_post_fgbg = argmax_images * fg_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply watershed method with the distance transform as seed\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "watershed_images = []\n",
    "for i in range(argmax_images_post_fgbg.shape[0]):\n",
    "    image = fg_thresh[i, ..., 0]\n",
    "    distance = argmax_images_post_fgbg[i, ..., 0]\n",
    "\n",
    "    local_maxi = peak_local_max(test_images[i, ..., -1],\n",
    "                                min_distance=15, \n",
    "                                exclude_border=False,\n",
    "                                indices=False,\n",
    "                                labels=image)\n",
    "\n",
    "    markers = label(local_maxi)\n",
    "    segments = watershed(-distance, markers, mask=image)\n",
    "    watershed_images.append(segments)\n",
    "\n",
    "watershed_images = np.array(watershed_images)\n",
    "watershed_images = np.expand_dims(watershed_images, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 0\n",
    "frame = 5\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(15, 15), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(X_test[index, frame, :, :, 0])\n",
    "ax[0].set_title('Source Image')\n",
    "\n",
    "ax[1].imshow(test_images_fgbg[index, frame, ..., 1])\n",
    "ax[1].set_title('Segmentation Prediction')\n",
    "\n",
    "ax[2].imshow(fg_thresh[index, frame, ..., 0], cmap='jet')\n",
    "ax[2].set_title('Thresholded Segmentation')\n",
    "\n",
    "ax[3].imshow(argmax_images[index, frame, ..., 0], cmap='jet')\n",
    "ax[3].set_title('Watershed Transform')\n",
    "\n",
    "ax[4].imshow(argmax_images_post_fgbg[index, frame, ..., 0], cmap='jet')\n",
    "ax[4].set_title('Watershed Transform w/o Background')\n",
    "\n",
    "ax[5].imshow(watershed_images[index, frame, ..., 0], cmap='jet')\n",
    "ax[5].set_title('Watershed Segmentation')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.utils.plot_utils import get_js_video\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(get_js_video(test_images_sample, batch=0, channel=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
